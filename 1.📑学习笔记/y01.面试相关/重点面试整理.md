---

title: 面试题整理
date: {{ date }}
top: false
cover: false
password:
toc: true
mathjax: true
summary:
tags: [面试] 
categories: []
---

# C++

## cpp是如何运行起来的？
【预处理阶段】：预处理根据#开头的命令，修改原始的程序，如把头文件插入到程序文本中，删除所有注释等。
【编译阶段】：编译过程就是把预处理完的文件进行一些了的词法分析、语法分析、语义分析等，最终产生相应的**汇编语言文件**，不同的高级语言翻译的汇编语言相同。编译是对源文件分别进行的，每个源文件都产生一个目标文件。
【汇编阶段】：把汇编语言翻译成目标机器指令
【链接阶段】：（主要是符号解析和重定位）将有关的目标文件和库文件相连接，使得所有的这些文件能够被操作系统装入执行的统一整体。

+ 符号解析

  在链接中，将函数和变量统称为符号，函数名和变量名统称为符号名，每个目标文件要提供两个符号表给链接器使用

  - 未解决符号表：本编译单元里有引用但是不在本单元定义的符号及其对应的地址。
  - 导出符号表：本单元定义，并且可提供给其他单元使用的符号及其在本单元对应地址。

  > 可以使用 nm 命令查出二进制文件包含的符号表。

  符号解析时，链接器根据目标文件提供的未解决符号表，去所有的编译单元的导出符号表中去查找与这个未解决符号相匹配的符号名，如果找到，就把这个符号的地址填到未解决符号的地址处，如果没有找到，就会报链接错误。

+ 重定位

  多个编译单元的符号地址可能是相同的，比如都从 (0x0000) 开始，那么最终多个目标文件链接时就会导致地址重复。

  所以链接器在链接时就会对每个目标文件的地址进行调整，这个调整的过程就是重定位。

链接处理分为两种：

+ 静态链接：静态链接时把要调用的函数或者过程连接到可执行文件中，称为可执行文件中的一部分。
+ 动态链接：**函数的代码被放到称作是动态链接或共享对象的某个目标文件中。链接程序要做的只是在最终的可执行文件中记录下相对应的信息。在可执行文件被执行时，根据可执行程序中记录的信息，将动态链接库的全部内容映射到相应运行程序的虚拟地址空间上**。

【运行】：最后，操作系统会加载可执行文件到内存中，并执行其中的代码。程序运行时会分配内存，执行指令，读写文件等操作，直到程序退出。

## C和C++的内存管理
c和c++的程序内存空间包括栈区、堆区、全局数据区、常量区、代码区
+ 栈区：由编译器自动分配释放，存放函数运行的局部变量，函数参数，返回数据，返回地址等。
+ 堆区：一般由程序员分配释放，若程序员不释放，程序结束时可能由操作系统回收。
+ 全局数据区：也叫静态区，存放全局变量，静态数据。程序结束后由系统释放。
+ 常量区：存放常量字符串等，其值不可变
+ 代码区：存放函数体的二进制代码。

## 基础语言特性

### c/cpp const关键字的作用

const单词字面意思为常数，不变的。它是c/c++中的一个关键字，是一个限定符，它用来限定一个变量不允许改变，它将一个对象转换成一个常量。

1. c语言全局const会被存储到只读数据段。c++中全局const当声明extern或者对变量取地址时，编译期会分配存储地址，变量存储在只读数据段。两个都受到了只读数据段的保护，不可修改

```c
const int constA = 10;
int main(){
   int* p = (int*)&constA;
   *p = 200;
}
```

以上代码在c/c++中编译通过，在运行期间，修改constA的值，发生写入错误。原因是修改只读数据段的数据。

2. c语言中局部const存储在堆栈区，只是不能通过变量直接修改const只读变量的值，但是可以跳过编译期的检查，通过指针间接修改const值

```c
const int constA = 10;
int* p = (int*)&constA;
*p = 300;
printf("constA:%d\n",constA);
printf("*p:%d\n", *p);
```

3. c++中的局部const变量：

+ 对于基础数据类型，也就是`const int a = 10`这种，编译器会把它放到符号表中，不分配内存，当对其取地址时，会分配内存。

  ```c++
  const int constA = 10;
  int* p = (int*)&constA;
  *p = 300;
  cout << "constA:" << constA << endl;
  cout << "*p:" << *p << endl;
  ```

  ```c++
  constA:10
  *p:300
  ```

  constA在符号表中，当我们对constA取地址，这时候为constA分配了新的空间，*p操作的时分配的空间，而constA是从符号表获得的值

+ 对于基础数据类型，如果用一个变量初始化const变量，如果const int a = b,那么也是会给a分配内存。

  ```c++
  int b = 10;
  const int constA = b;//会分配空间
  int* p = (int*)&constA;
  *p = 300;
  cout << "constA:" << constA << endl;
  cout << "*p:" << *p << endl;
  ```

  ```c++
  constA:300
  *p:300
  ```

  constA分配了内存，所以我们可以修改constA内存中的值

+ 对于自定义数据类型，比如类对象，那么也会分配内存

  ```c++
  const Person person; //未初始化age
  //person.age = 50; //不可修改
  Person* pPerson = (Person*)&person;
  //指针间接修改
  pPerson->age = 100;
  cout << "pPerson->age:" << pPerson->age << endl;
  pPerson->age = 200;
  cout << "pPerson->age:" << pPerson->age << endl;
  ```

  ```c++
  pPerson->age:100
  pPerson->age:200
  ```


### c/cpp static关键字

控制变量的存储方式和可见性

1. 修饰局部变量：存放在静态存储区，生命周期会一直延续到整个程序执行结束，作用域还是限制在局部。
2. 修饰全局变量/函数：static改变了原来全局变量的作用域范围，由原来整个工程可见变为了本文件可见
3. 修饰类函数：表示该函数属于一个类而非示例；若对类中某变量修饰，则表示该变量被所有该类实例所共有，static修改的类变量下怒对象存在，所以其要在类外初始化。

### 指针和引用的区别
1. 指针是一个变量，这个变量存储的是一个地址，指向内存的一个存储单元；而引用相当于原来变量的一个别名
2. 指针定义时不必初始化，引用定义是必须初始化
3. 指针定义是可以初始化为NULL，引用不能初始化为NULL
4. 非常指针在指针赋值后可以改变指针值；引用在初始化后不能再作为别的变量的别名
5. siezeof 运算符作用于指针变量得到指针变量自身的大小；作用于引用，得到引用所指向的变量的大小。
6. 指针可以有多级，引用只有一级


### c++中的四种类型转换
+ static_cast（静态类型转换）
  + 静态类型转换，编译时c++编译器会做类型检查，基本类型能转换但是不能转换指针类型。
+ reinterpreter_cast（重新解释类型转换）
  + static_cast对于基本类型可以转换，但是不能转换指针类型
  + 若不同类型之间，进行强制类型转换，用reinterpret_cast进行重新解释
+ dynamic_cast（动态类型转换）
  + c++中重要的，安全的基类和子类之间转换，运行时类型检查
  + dynamic_cast可以将一个基类对象指针（或引用）转换到继承类指针，dynamic_cast会根据基类指针是否真正指向继承类指针来做相应处理。
+ const_cast（常量类型转换）
  + 去除变量的只读属性
  + const_cast 是用来移除变量的const或volatile限定符。

### new和malloc的区别

1. 申请的内存所在的位置

   new操作符从**自由存储区（free store）**上为对象动态分配内存空间，而malloc函数从**堆**上动态分配内存。自由存储区是C++基于new操作符的一个抽象概念，凡是通过new操作符进行内存申请，该内存即为自由存储区。而堆是操作系统中的术语，是操作系统所维护的一块特殊内存，用于程序的内存动态分配，C语言使用malloc从堆上分配内存，使用free释放已分配的对应内存。

   那么自由存储区是否能够是堆（问题等价于new是否能在堆上动态分配内存），这取决于operator new 的实现细节。自由存储区不仅可以是堆，还可以是静态存储区，这都看operator new在哪里为对象分配内存。

2. 返回类型安全性

   new操作符内存分配成功时，返回的是对象类型的指针，类型严格与对象匹配，无须进行类型转换，故new是符合**类型安全**性的操作符。而malloc内存分配成功则是返回void * ，需要通过强制类型转换将void*指针转换成我们需要的类型。

3. 内存分配失败时的返回值

   new内存分配失败时，会抛出bac_alloc异常，它**不会返回NULL**；malloc分配内存失败时返回NULL。

4. 是否需要指定内存大小

   使用new操作符申请内存分配时无须指定内存块的大小，编译器会根据类型信息自行计算，而malloc则需要显式地指出所需内存的尺寸。

5. 是否调用构造函数/析构函数

   使用new操作符来分配对象内存时会经历三个步骤：

   - 第一步：调用operator new 函数（对于数组是operator new[]）分配一块足够大的，**原始**的，未命名的内存空间以便存储特定类型的对象。
   - 第二步：编译器运行相应的**构造函数**以构造对象，并为其传入初值。
   - 第三部：对象构造完成后，返回一个指向该对象的指针。

   使用delete操作符来释放对象内存时会经历两个步骤：

   - 第一步：调用对象的析构函数。
   - 第二步：编译器调用operator delete(或operator delete[])函数释放内存空间。

   总之来说，new/delete会调用对象的构造函数/析构函数以完成对象的构造/析构。而malloc则不会。

6. 对数组的处理

   C++提供了new[]与delete[]来专门处理数组类型；

   至于malloc，它并不知道你在这块内存上要放的数组还是啥别的东西，反正它就给你一块原始的内存，在给你个内存的地址就完事。所以如果要动态分配一个数组的内存，还需要我们手动自定数组的大小

7. new与malloc是否可以相互调用

   operator new /operator delete的实现可以基于malloc，而malloc的实现不可以去调用new。

8. 是否可以被重载

   opeartor new /operator delete可以被重载。

   而malloc/free并**不允许重载**

9. 能够直观地重新分配内存

   使用malloc分配的内存后，如果在使用过程中发现内存不足，可以使用realloc函数进行内存重新分配实现内存的扩充。realloc先判断当前的指针所指内存是否有足够的连续空间，如果有，原地扩大可分配的内存地址，并且返回原来的地址指针；如果空间不够，先按照新指定的大小分配空间，将原有数据从头到尾拷贝到新分配的内存区域，而后释放原来的内存区域。

   new没有这样直观的配套设施来扩充内存。

10. 客户处理内存分配不足  

    在operator new抛出异常以反映一个未获得满足的需求之前，它会先调用一个用户指定的错误处理函数，这就是new-handler。

    对于malloc，客户并不能够去编程决定内存不足以分配时要干什么事，只能看着malloc返回NULL。

## 智能指针
+ unique_pointer
+ shared_pointer
+ weak_pointer

在c++中，内存泄漏的主要原因就是程序员在申请内存后没有及时释放没用的内存空间，甚至消灭了指针后导致该区域内存空间没发释放。
为了减少出现这种内存泄漏的情况，STL中使用了智能指针，智能指针是一个类，这个类的构造函数中传入一个普通指针，析构函数中释放传入的指针。智能指针的类都是栈上的对象，所以当函数或程序结束是会被自动释放。

具体分为unique_ptr（独占指针）, shared_ptr（共享指针）,和 weak_ptr:

+ 独占指针就是同一时刻只能由一个指针指向动态分配的资源，内部禁止拷贝和赋值，但是有移动构造函数

+ 共享指针就是同一时刻可以有多个指针指向同一个动态分配的资源，内部通过一个引用计数表示该资源被多少个指针指向。当一个共享指针离开作用域时，会将引用计数减一，引用计数为0时才真正释放资源。

+ 为了解决共享指针的循环引用[循环引用](https://www.cnlzhnn.com/%E6%B5%85%E8%B0%88shared_ptr%E5%BE%AA%E7%8E%AF%E5%BC%95%E7%94%A8%E9%97%AE%E9%A2%98/)的问题，引入了weak pointer, 一个弱指针指向一个共享对象时不会增加引用计数。
### unique_pointer
```c++
template<typename T>
class unique_ptr{
public:
	unique_ptr(T* ptr_ = nullptr):ptr(ptr_){}
	~unique_ptr(){
		if(ptr) delete ptr;
	}

	unique_ptr(unique_ptr&& rhs){
		ptr = rhs.release();
	}

	unique_ptr& operator= (unique_ptr rhs){
		rhs.swap(*this);
		return *this;
	}

	void swap(unique_ptr& rhs){
		using std::swap;
		swap(ptr, rhs.ptr);
	}

	unique_ptr& release(){
		T* ptr_ = ptr;
		ptr = nullptr;
		return ptr_;
	}
private:
	T* ptr;
}
```

### shared_pointer
```c++
class Count{
public:
	Count():cnt(0){}
	void add_count(){
		cnt++;
	}
	long reduce_count(){
		return --cnt;
	}
	int get_count(){
		return cnt;
	}

private:
	long cnt;
};

template<typename T>
class Shared_ptr{
public:
	Shared_ptr(T* ptr_ = nullptr):ptr(ptr_){
		if(ptr) cnt = new Count();
	}
	~Shared_ptr(){
		if(ptr&&!cnt.reduce()){
			delete cnt;
			delete ptr;
		}
	}

	Shared_ptr(const Shared_ptr& other){
		ptr = other.ptr;
		if(ptr){
			cnt = other.cnt;
			cnt_.add_count();
		}
	}

	Shared_ptr(Shared_ptr&& other){
		ptr_ = other.ptr;
		if(ptr_){
			other.ptr = nullptr;
			cnt = other.cnt;
		}
	}

	Shared_ptr& operator= (Shared_ptr rhs){
		rhs.swap(*this);
		return *this;
	}

	void swap(Shared_ptr& rhs){
		using std::swap;
		swap(ptr, rhs.ptr);
		swap(cnt, rhs.cnt);
	}

private:
	Count* cnt;
	T* ptr;
}
```

## STL相关
### STL中常见容器的实现原理
STL容器分为序列性容器和关联性容器
序列性容器
+ array:固定大小的顺序容器，它们保存了一个以严格的线性顺序排列的特定数量的元素
+ vector动态数组
	+ 动态空间，随着元素的加入，它的内部机制会自行扩充空间以容纳新元素。vector的数据结构其实就是三个迭代器构成的，一个指向目前使用的空间头，一个指向目前使用的空间尾，一个指向目前可用的空间尾。当有新元素插入时，如果目前容量够则直接插入；如果不够则扩充至两倍，依次类推。扩充的过程时重新申请一块连续内存，将原有数据拷贝到新空间，再释放原有空间，扩充后原有的迭代器会失效。
	+ remove()的实现原理：在遍历容器中的元素时，一旦遇到目标元素，就做上标记，然后继续遍历，知道找到一个非目标元素，用此元素将最先做标记的位置覆盖掉，同时将此目标元素所在的位置也做上标记，等待找到新的非目标元素将其覆盖。remove()不会该表其容量大小，而erase()可以改变其容量大小，通常将remove()返回的迭代器传入erase()中清除后续无用的元素。
	+ 注意事项：
		+ 插入和删除元素后，由于内存重分配则会导致迭代器全部失效；没有重分配则插入和删除之后的迭代器失效
		+ 清空vector数据时，如果保存的数据项是指针类型，需要逐项delete，否则会造成内存泄漏
		+ 频繁调用push_back的影响：向vector的尾部添加元素，很可能引起整个对象存储空间的重新分配，这个过程是耗时耗力的。C++11之后，新增emplace_back()方法，都是添加元素，但是该方法效率更高。emplace_back在内存优化方面和运行效率方面有改下，内存优化方面主要体现在就地构造（直接在容器内构造对象，不用拷贝一个再使用）+强制类型转换，由于省去了拷贝构造，效率有提高。
+ list链表：双向链表，常量性能的增删，不支持随机访问
+ deque
	+ 支持从头尾两端进行元素的插入和删除操作，没有容量的概念，因为它是动态地以【分段连续空间】组合而成，随时可以增加一段新的空间并连接起来，但是拥有复杂的迭代器结构。deque采用一块所谓的map作为主控，这里的map实际就是一块大小连续的空间，其中每一个元素都称为节点node,都指向了另一段连续线性空间，该空间是deque真正的存储空间。
	+ 实现原理
		+ 迭代器是一个类，其中迭代器中的node变量指向map的一个单元，而map中的每个单元指向当前迭代器对应的数据（缓冲区）。
		+ 当某个缓冲区头部或尾部已满时，将回到map中定位到相邻的数据缓冲区。内部分段连续实现
		+ 当插入元素时，当前位置位于首部或尾部时，直接插入；否则比较当前元素距离首部近还是尾部近，距离那边近则将当前位置那段的元素整体移动，再插入当前元素
		关联性容器
+ map,multimap: 以Key建立的红黑树
+ set, multiset：红黑树，multiset支持重复，而set会去重
+ unordered_map：
	+ 所有无序容器的底层实现都是Hash Map
	+ 无序容器存储键值对时，会先申请一整块连续的存储空间，但此空间并不是来直接存储键值对，而是存储各个链表的的头指针，称之为【桶】，各个键值对真正存储位置是各个链表的节点

### STL中resize()和reserve()的区别
+ resize(n)是调整容器的长度大小，使其能容纳n个元素，如果n小于容器的当前size,则删除多出来的元素，否则添加采用值初始化的元素
+ resize(n,t)多一个参数t, 将所有新添加的元素初始化为t
+ reserver(n)预分配n个元素的存储空间
+ 两者的区别主要是容器的capacity和size的区别
	+ size是指容器当前拥有的元素个数
	+ capacity是指容器必须分配新存储空间之前可用存储的元素总数，即预分配存储空间的大小

## 面向对象
三大特性：封装、继承、多态

### 谈一谈对多态的理解
通过父类的指针指向子类的对象，达到重写函数的目的。
一句话定义：多态就是一个函数的多种形态，比较常见的就是函数重载和函数重写，也就是函数静态多态和动态多态。
下面我分开说说我对这两种多态的理解。
函数重载也叫编译时多态，就是在同一个作用域下有相同的函数名，不同的函数签名（比如函数参数列表不同等）的函数。如果没有函数重载，很多功能相似但是不完全相同的函数就要取很多不同的名字，比如double和int等等不同类型的参数对应的加法函数就不相同，就要实现很多不同名称的函数，函数重载使得代码编写更加合理。然后cpp函数重载底层汇编代码实现其实还是对这些不同函数命了不同的名称，每个函数对应不同的函数签名，而c语言反汇编后的代码则没有这样的处理，所以c语言不支持重载。
另一种就是函数重写，是指在派生类中覆盖基类中的同名函数，也叫函数覆盖，要求基类函数必须是虚函数，我也研究过函数重写的原理，基类中如果有虚函数，编译器会自动为每个含有虚函数的类生成一份虚表，可以理解为一个一维数组，虚表里面保存了虚函数的入口地址，编译的时候会在每个对象的前四个或八个字节中保存一个虚表指针，这个虚表指针指向所属类的虚表，在构造的时候，根据对象的类型初始化虚表指针，从而让虚表指针指向正确的虚表，在调用虚函数的时候能找到正确的函数，这个虚表在运行是是不能被修改的，而且全局可见，所以不是放在堆区，栈区，也不是放在代码区，全局区，而是放在常量区。

### 构造函数可以是虚函数吗？析构函数为什么定义为虚函数？
+ 先构造函数，再初始化虚函数表，如果构造函数为虚函数，当创建对象时，就需要去找虚函数表，但是此时虚函数表还没有初始化。
+ 析构函数定义为虚函数是为了防止内存泄漏，因为当基类的指针或引用指向或绑定到派生类的对象时，如果未将析构函数定义为虚函数，只会调用基类的析构函数，那么只能将基类的程序所占用的空间释放掉，派生类中特有的就无法释放内存空间，导致内存泄漏。
+ 我们将析构函数定义为虚函数，再指向析构时，则根据对象的类型来指向析构函数，此时派生类的资源得到释放

### 为什么拷贝构造函数必须是引用传递？
为了防止递归调用。当一个对象需要以值方式传递时，编译器会生成代码调用它的拷贝构造函数生成一个副本，如果该类的拷贝构造函数的参数不是引用传递，而是值传递，那么就需要创建传递给拷贝构造函数参数的临时对象，而又一次调用该类的拷贝构造函数，无限递归。


# 数据结构与算法

## 红黑树
+ 每个节点是红色或者黑色，根节点必须是黑色的
+ 红色节点的孩子节点必须是黑色的，黑色节点则无要求
+ 从根节点到任意叶子节点都包含相同数量的黑色节点
+ 红黑树的高度最多是`2*log_2 (n+1)`

## 排序算法
分析以下几种排序方法的时空复杂度和稳定性
+ 冒泡排序
+ 快速排序
+ 归并排序
+ 堆排序

![image-20230330225825483](https://raw.githubusercontent.com/mowang111/image-hosting/master/typora_images/image-20230330225825483.png)

# 计网
## 键入网址到网页显示，期间发生了什么？
![image.png](https://raw.githubusercontent.com/mowang111/image-hosting/master/typora_images/20230221230905.png)

1. 浏览器做的第一步工作就是解析URL
2. 经过URL进行解析之后，浏览器确定了Web服务器和文件名，接下来就是根据这些信息来生成HTTP请求消息
3. 在发送消息之前，需要查询服务器域名对应的IP地址——DNS协议(首先是查询缓存有没有对应域名，然后看hosts文件，最后才会去问【本地DNS服务器】)
4. 通过DNS获取到IP后，将HTTP的传输工作交给操作系统中的协议栈。 
![image.png](https://raw.githubusercontent.com/mowang111/image-hosting/master/typora_images/20230221232124.png)
应用程序（浏览器）通过调用Socket库，来委托协议栈工作。协议栈的上半部分有两块，分别是负责收发数据的TCP和UDP协议，这两个传输协议会接受应用层的委托执行收发数据的操作

协议栈的下面一半是用IP协议控制网络包收发操作，在互联网上传数据时，数据会被切分成一块块的网络包，而将网络包发送给对方的操作就是由IP负责。

此外IP中还包括ICMP协议和ARP协议
+ ICMP用于告知网络包传送过程中产生的错误以及各种控制信息。
+ ARP用于根据IP地址查询相应的以太网MAC地址

IP下面的网卡驱动程序负责控制网卡硬件
+ 当存在多个网卡时，在填写源地址IP时，就需要判断到底应该填写哪个地址。这个判断相当于在多块网卡中判断应该使用哪个网卡发送包
	+ 这时候需要根据【路由表规则】，来判断哪个网卡作为源地址IP。
		+ IP地址分别和路由表中对应的子网掩码进行与运算，发现和目的IP匹配，则确定发送的网卡

最下面的网卡则负责完成实际的收发操作，也就是对网线中的信号执行发送和接收操作
+ 在生成了IP头部之后，接下来网络包还需要在IP头部前面加上MAC头部
+ 一般在TCP/IP通信里，MAC包头协议类型只使用：
	+ 0800：IP协议
	+ 0806：ARP协议
+ MAC头部里需要发送方MAC地址和接收方的目标MAC地址，用于两点之间的传输
+ 那么如何知道接收方的MAC地址呢？
	+ 首先在路由表中已经查到下一跳的目标IP
	+ 然后使用ARP协议找到对应MAC地址


网络包只是存放在内存中的一串二进制数字信息，没办法直接发送给对方，需要使用网卡将数字信号转换为电信号，要控制网卡还需要靠网卡驱动程序。
+ 网卡驱动获取网络包之后，会将其复制到网卡内的缓存区中，接着会在其开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列


网络包到达交换机，交换机根据MAC地址表查找MAC地址，然后将信号发送到相应的端口。
+ 交换机的MAC地址表主要包含两个信息：
	+ 一个是设备的MAC地址
	+ 一个是该设备连接在交换机的哪个端口上
+ 如果地址表中找不到指定的MAC地址，可能是因为具有该地址的设备还没有向交换机发送过包，或者这个设备一段时间没有工作导致地址被从地址表中删除了。这种情况下，交换机将包转发到除源端口之外的所有端口。

>计算机的网卡本身具有MAC地址，并通过核对收到的包的接收方MAC地址判断是不是发给自己的，如果不是发给自己的则丢弃；相对地，交换机的端口不核对接收方的MAC地址，而是直接接收所有的包并存放到缓冲区。因此，和网卡不同，交换机的端口不具有MAC地址。


网络包经过交换机之后，到达了路由器，并再次被转发到了下一个路由器或目标设备
+ 路由器是基于IP设计的，是三层网络设备，路由器的各个端口都具有MAC地址和IP地址
+ 而交换机是基于以太网设计的，是二层网络设备，交换机的端口不具有MAC地址

当转发包时，首先路由器端口会接收发给自己的以太网包，然后路由表查询转发目标，再由相应的端口作为发送方将以太网包发送出去
+ 路由器会检测MAC头部的接收方MAC地址，判断是否是发给自己的 
+ 完成包接收操作之后，路由器就会去掉包开头的MAC头部，MAC头部的作用就是将包送达路由器
+ 接下来，路由器会根据MAC头部后方的IP头部中的内容进行包的转发
	+ 首先查询路由表判断转发目标
	+ 进入包的发送操作
		+ 根据路由表的【网关列】判断对方的地址
			+ 如果网关是一个IP，就需要继续路由器转发
			+ 如果网关为空，则IP头部中的接收方IP地址就是要转发的目标地址
		+ 再次使用ARP协议根据IP地址查询MAC地址

数据包到达服务器后，服务器就会以此检查MAC头部，IP头部，TCP头部，到达HTTP进程，然后返回HTTP响应报文。

## ISO七层模型，TCP/IP四层模型，以及每层模型的协议
### OSI七层模型
1. 物理层：确保原始数据可以在各种物理媒介上传输。这一层是bit流。传输协议有IEEE 802.1A等。
2. 数据链路层：在不可靠的物理介质上提供可靠的传输。包括物理地址寻址、流量控制、数据的检错和重发。这一层将bit流封装成frame帧。传输协议有MAC等。
3. 网络层：负责对子网间的数据包进行路由选择，目的是实现两个端系统之间的数据透明传送。这一层数据的单位是数据包。协议有IP、ICMP、ARP、RARP等。
4. 传输层：负责将上层数据分段并提供端到端的传输。这一层数据的单位称为数据段（segment），传输协议有TCP、UDP等
5. 会话层：管理主机之间的会话进程，如建立会话、session认证、断点续传等。传输协议有SMTP等。
6. 表示层：主要解决用户信息的语法表示问题。数据的压缩和解压缩、加密和解密等工作由该层负责。
7. 应用层：为操作系统或网络应用程序提供访问网络服务的接口。传输协议由FTP、HTTP、Telnet、DNS等。
### TCP/IP四层模型
+ 应用层
	+ HTTP
	+ FTP
	+ SMTP
	+ TELNET
	+ DNS
		+ 域名系统（Domain Name System）是域名映射IP地址的分布式数据库，端口号53
	+ DHCP
		+ 动态主机配置协议（Dynamic Host Configuration Protocol）的主要作用是集中管理、动态分配IP地址，提升地址的使用率
+ 传输层
	+ TCP
	+ UDP
+ 网络层
	+ IP
		+ 网际协议（Internet Protocol）是用于分组交换数据的一种协议，功能包括寻址、路由、尽最大努力交付数据包
	+ ICMP
		+ 互联网控制消息协议（Internet Control Message Protocol）用于返回同学环境的错误消息。分为两类，一类是【差错报文】，这类报文主要用来响应网络错误，比如目标不可达和重定向，比如traceroute是通过发送含有特殊TTL的包，定位到目标主机之间的所有路由器；另一类是查询报文，这类报文用来查询网络信息，比如ping程序利用此类报文查看目标是否可达。ICMP报文使用16位校验和字段对整个报文（包括头部）进行循环冗余校验（CRC），以检验报文在传输过程中是否损坏
	+ IGMP
		+ 因特网组管理协议（Internet Group Management Protocol）管理IP协议多播组成员
	+ OSFP
		+ 开放式最短路径优先（Open Shortest Path First）是一种内部网关协议（IGP）,使用Dijkstra算法计算最短路径，是链路状态路由协议的一种实现。
+ 数据链路层
	+ ARP*
		+ 地址解析协议（Address Resolution Protocol）通过IP寻找MAC地址。
		+ 工作原理：主机向自己所在的网络广播一个ARP请求，该请求包含目标机器的网络地址。此网络上的其他机器都将收到这个请求，但只有被请求的目标会回应一个ARP应答，其中包含自己的物理地址。
+ 物理层
	+ IEEE802
		+ IEEE802指IEEE标准中关于局域网和城域网的一系列标准，其中最广泛使用的有以太网、令牌环、无线局域网等。
> ARP协议属于哪一层？一种说法是属于网络层，因为IP协议使用ARP协议；另一种说法是属于数据链路层，因为MAC地址是数据链路层的内容。在OSI模型中，ARP协议属于数据链路层；而在TCP/IP模型中，ARP协议属于网络层。


## HTTP
请求报文由请求行、请求头、（空行以及）消息体组成
响应报文由状态行、响应头、（空行以及）消息体组成
### GET和POST的区别
GET是从服务器获取指定资源，比如静态文本，页面，图片，视频等。GET请求的参数位置一般是写在URL中，URL规定只能支持ASCII，所以GET请求的参数只允许ASCII字符，而且浏览器会对URL的长度有限制（HTTP协议本身对URL的长度没有任何规定）。
POST是对指定的资源进行处理，具体的处理方式视资源的类型而不同。POST请求携带的数据位置一般是写在报文body中，body中的数据可以是任意格式的数据，只要客户端和服务端协商好，而且浏览器不会对body大小做限制。
+ 作用上：GET获取服务器资源，可被缓存，POST添加/修改服务器资源，不能被缓存
+ 幂等/安全性：GET是幂等安全的，POST是非幂等不安全的
+ 参数位置：GET暴露在URL链接中，POST在消息体中
+ 参数长度：GET由浏览器限制，POST无限制

### HTTPS
HTTPS解决了HTTP的哪些问题？
+ 窃听风险，比如通信链路上可以获取通信内容
+ 篡改风险，比如强制植入垃圾广告
+ 冒充风险，比如冒充淘宝网站

HTTPS在HTTP和TCP层之间加入了`SSL/TLS`协议，解决上述问题：
+ 信息加密：交互信息无法被窃取
+ 校验机制：无法篡改通信内容，篡改了就不能正常显示
+ 身份证书：证明网站的真实性

如果解决上述问题的：
+ **混合加密**的方式实现信息的机密性，解决了窃听的风险
+ **摘要算法**的方式来实现完整性，它能够为数据生成独一无二的指纹，指纹用于校验数据的完整性，解决了篡改的风险
+ 将服务器公钥放入到**数字证书**中，解决了冒充的风险。
![image.png](https://raw.githubusercontent.com/mowang111/image-hosting/master/typora_images/20230322150912.png)



### HTTP协议版本
![image.png](https://raw.githubusercontent.com/mowang111/image-hosting/master/typora_images/20230218215342.png)

#### HTTP/1.1
简答，灵活和易于扩展、应用广泛和跨平台
HTTP协议里的各类请求方法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发人员自定义和扩充
同时HTTP由于是工作在应用层，它下层可以随意变化
+ HTTPS就是在HTTP与TCP层之间增加了SSL/TLS安全传输层；
+ HTTP/1.1和HTTP2.0传输协议用的是TCP协议，而到了HTTP/3.0 传输层协议改用了UDP协议
HTTP协议有优缺点一体的双刃剑，分别是【无状态、明文传输】，不安全
性能：长连接、管道网络传输（有这个功能，没有被使用）->队头阻塞

##### HTTP/1.1相比HTTP/1.0性能上的改进
+ 使用长连接的方式改善了HTTP/1.0短连接造成的性能开销，不过长连接会占用服务器资源
+ 支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间
##### 性能瓶颈
+ 请求/响应头部未经压缩发送，首部信息越多延迟越大，且每次互相发送相同的首部造成的浪费较多
+ 服务器是按请求的顺序响应的，如果服务器响应慢，会导致客户端一直请求不到数据，也就是队头阻塞；
+ 没有请求优先级控制；
+ 请求只能从客户端开始，服务器只能被动响应
##### 如何优化？
+ 尽量避免发送HTTP请求：尽量使用缓存处理。
+ 尽量减少请求次数：利用代理服务器等减少重定向请求次数；合并请求资源；延迟发送请求。
+ 减少响应的数据大小：通过有损或无损压缩对响应的资源进行压缩
#### HTTP/2.0
HTTP/2协议是基于HTTPS的
改进点：
1. Header压缩：头部的编码通过【静态表（保存常用字段编码并固定在协议中）、动态表（动态添加静态表中没有的字段编码）、Huffman编码】共同完成。
2. 二进制分帧：HTTP/1.x采用文本格式传输数据。HTTP/2.0将所有传输信息分割为若干个帧，采用二进制格式进行编码。具体实现上，是在应用层（HTTP）和传输层（TCP）之间增加一个二进制分帧层。每个请求对应一个流，有个唯一的标识符。请求报文会被拆分为一个或多个帧（帧头+消息负载），每个帧有序列号，以及自己所属流的标识符，接收端自行合并。同时，二进制分帧采用的流传输也为多路复用提供了基础。
3. 多路复用：每个请求或响应的数据包称为一个数据流，每个数据流都有唯一的编号，因此不同流的帧可以乱序发送（即可以并发不同的流）。因为每个帧的头部会携带流编号信息，所以接收端可以通过流编号有序拼接HTTP消息。客户端和服务器双方都可以建立流，其中客户端建立的流编号必须是奇数号，而服务器建立的流编号必须是偶数号。客户端还可以指定数据流的优先级。
4. 服务端推送：服务端会根据客户端的请求，提前推送额外的资源给客户端，可以减轻数据传输的冗余步骤，同时加快页面响应速度，提升用户体验。比如在发送页面HTML时主动推送其它CSS/JS资源，而不用等到浏览器解析到相应位置，发起请求再相应。

HTTP/2.0缺陷：

+ HTTP队头阻塞。HTTP/2是基于TCP协议来传输数据的，TCP是字节流协议，TCP层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给HTTP应用，那么当【前1个字节数据】没有到达时，后受到的字节数据只能存放再内核缓冲区里，只有等到这1个字节数据到达时，HTTP/2应用层才能从内核中拿到数据，这就是HTTP/2队头阻塞问题。所以，一旦发送了丢包现象，就会触发TCP的重传机制，这样在一个TCP连接中的所有的HTTP请求都必须等待这个丢了的包被重传回来。
+ 慢启动降低效率。TCP由于具有【拥塞控制】的特性，所以刚建立连接的TCP会有个【慢启动】的过程，它会对TCP连接产生“减速”效果。
+ 网络切换重连。一个TCP连接是由四元组（源IP地址，源端口，目标IP地址，目标端口）确定的，这意味着如果IP地址或者端口变动了，就会导致需要TCP于TLS重新握手，不利于移动设备切换网络的场景，比如4G网络环境切换成WIFI。
#### HTTP/3.0/QUIC
HTTP/3优化：
+ 改进头部压缩算法。HTTP/3中的QPACK也采用了静态表、动态表以及Huffman编码。HTTP/2和HTTP/3的动态表编解码方式不同，QUIC会有两个特殊的单向流，这两个特殊的单向流是用来同步双方的动态表，编码方收到解码方更新确认的通知后，才使用动态表编码HTTP头部
+ 更换传输协议。HTTP/2虽然通过多个请求复用一个TCP连接解决了HTTP的队头阻塞，但是一旦发生丢包，就会阻塞住所有的HTTP请求，这属于TCP层队头阻塞。所以HTTP/3把HTTP下层的TCP协议改成了UDP，基于UDP的QUIC协议可以实现类似TCP的可靠传输

QUIC实现了两种级别的流量控制，分别为Stream和Connection两种级别：
+ Stream流量控制：每个HTTP请求对应一个流，每个Stream都有独立的滑动窗口，所以每个Stream都可以做流量控制，防止单个Stream占用连接的全部接收缓冲。
+ Connection流量控制：限制连接中所有Stream加起来的总字节数，防止发送方超过连接的缓冲容量。

QUIC有以下3个特点：
+ 无队头阻塞：当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞的问题。而HTTP/2只要某个流中的数据包丢失了，其他流也会受到影响。
+ 更快的建立连接：对于HTTPS和HTTP/2协议，TCP和TLS时分层的，需要分批次来握手，先TCP握手，再TLS握手。HTTP/3在传输数据前虽然需要QUIC协议握手，这个握手过程只需要1RTT，握手的目的是为了确认双方的【连接ID】,连接迁移就是基于连接ID实现的。不过QUIC协议并不是与TLS分层，其内部包含了TLS，再加上QUIC使用的是TLS/1.3，因此仅需1个RTT就可以【同时】完成建立连接与密钥协商。
+ 连接迁移：基于TCP传输协议的HTTP协议，由于是通过四元组（源IP，源端口，目的IP、目的端口）确定一条TCP连接，那么当移动设备的网络从4G切换到WIFI时，意味着IP地址变化了，那么就必须要断开连接，然后重新建立连接。而建立连接的过程包含TCP三次握手和TLS四次握手的时延，以及TCP慢启动的减速过程，给用户的感觉时网络突然卡顿，因此连接的迁移成本很高。
	+ 而QUIC协议没有用四元组的方式绑定连接，而是通过连接ID来标记通信的两个端点，客户端和服务器可以各自选择一组ID来标记自己，因此即使移动设备的网络IP地址变化了，只要仍保有上下文信息（比如连接ID、TLS密钥等），就可以“无缝”地复用原连接。

## TCP
### TCP和UDP的区别
TCP是面向连接的、端对端的、基于字节流的可靠传输层协议，而UDP不需要连接、支持多对多的、一个包一个包发送的不可靠传输层协议。
此外，TCP的首部开销较长，在没有使用【选项】字段时是20个字节，而UDP首部只有8个字节，固定不变，开销较小
TCP拥有流量控制和拥塞控制，而UDP则没有，即使网络拥堵，也不会影响UDP的发送速率
另外，TCP的数据大小如果大于MSS（最大报文长度）大小，会在传输层进行分片，UDP的数据大小如果大于MTU（最大传输大小），则会在IP层进行分片。

### TCP 三次握手和四次挥手过程
三次握手
![image.png](https://raw.githubusercontent.com/mowang111/image-hosting/master/typora_images/20230124232346.png)
TCP是面向连接的协议，所以使用TCP前必须先建立连接，而建立连接时通过三次握手来进行的，其过程如下：
+ 一开始，客户端和服务器都处于`CLOSE`状态。先是服务端主动监听某个端口，处于`LISTEN`状态
+ 客户端会随机初始化序号（`client_isn`），将此序号置于TCP首部的序号字段中，同时把`SYN`标志位置设为1，表示`SYN`报文，然后把第一个`SYN`报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于`SYN-SENT`状态。
+ 服务端收到客户端的`SYN`报文后，首先服务端也随机初始化自己的序号（`server_isn`）,将此序号填入TCP首部的序号字段，其次把TCP首部的确认应答号字段填入`client_isn + 1`, 接着把`SYN`和`ACK`标志位置设为1，最后把报文发给客户端，该报文也不包含应用层数据，之后服务端处于`SYN-RCVD`状态。
+ 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文TCP首部`ACK`标志位置设为1，其次确认应答号字段填入`server_isn + 1`，最后把报文发送给服务端，这次报文可以写道客户到服务端的数据，之后客户端处于`ESTABLISHED`状态。
+ 服务端收到客户端的应答报文后，也进入`ESTABLISHED`状态

四次挥手
![image.png](https://raw.githubusercontent.com/mowang111/image-hosting/master/typora_images/20230124232355.png)

TCP断开连接
双方都可以主动断开连接，断开连接后主机中的资源将被释放，四次挥手的过程如下：
+ 客户端打算关闭连接，会发送一个TCP首部`FIN`标志位被置为1的报文，也即`FIN`报文，之后客户端进入`FIN_WAIT_1`状态
+ 服务端收到该报文后，就向客户端发送`ACK`应答报文，接着服务端进入`CLOSE_WAIT`状态
+ 客户端收到服务端的`ACK`应答报文后，之后进入`FIN_WAIT_2`状态
+ 等待服务端处理完数据后，也向客户端发送`FIN`报文，之后服务器进入`LAST_ACK`状态。
+ 客户端收到服务端的`FIN`报文后，回一个`ACK`应答报文，之后进入`TIME_WAIT`状态
+ 服务端收到了`ACK`应答报文后，就进入了`CLOSE`状态，至此服务端已经完成连接的关闭
+ 客户端在经过`2MSL`一段时间后，自动进入`CLOSE`状态，至此客户端也完成了连接的关闭

主动关闭连接的，才有 TIME_WAIT 状态。

#### 为什么是三次握手？不是两次、四次？
+ 三次握手才可以阻止重复历史连接的初始化（主要原因）
	+ 当客户端发送SYN报文后宕机，客户端重启后重新发送一个新的SYN报文，当服务器先收到旧SYN报文，返回SYN+ACK，客户端发现确认号对不上，于是发给服务端RST报文以释放连接，新的SYN+ACK到达后，开始正常完成三次握手
	+ 在两次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接，造成资源浪费
+ 三次握手才可以同步双方的初始序列号
	+ TCP协议的通信双方，都必须维护一个【序列号】，序列号是可靠传输的一个关键因素，他的作用：
		+ 接收方可以去除重复的数据
		+ 接收方可以根据数据包的序列号按序接收
		+ 可以标识发送出去的数据包中，哪些是已经被对方收到的(通过ACK报文中的序列号知道)
+ 三次握手才可以避免资源浪费
#### 为什么需要四次挥手？
+ TCP是全双工的，关闭连接时，客户端向服务端发送`FIN`时，仅仅表示客户端不再发送数据了但还是能接收数据
+ 服务端收到客户端的`FIN`报文时，先回一个`ACK`应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送`FIN`报文给客户端来表示同意现在关闭连接
从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的`ACK`和`FIN`一般都是分开发送的，因此需要四次挥手。

#### 为什么需要TIME_WAIT状态？为什么TIME_WAIT等待时间是2MSL?
MSL:Maximum Segment Lifetime，报文最大生存时间，他是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。

+ 确保ACK报文能够到达服务端，从而使服务端正常关闭连接。
	+ 第四次挥手时，客户端第四次挥手的ACK报文不一定会到达服务端。服务端会超时重传FIN/ACK报文，如果此时客户端已经断开连接，那么就无法响应服务端的二次请求，这样服务端迟迟收不到FIN/ACK报文的确认，就无法正常断开连接。MSL时报文段在网络上存活 最长时间，客户端等待2MSL时间，即【客户端ACK报文1MSL超时+服务端FIN报文1MSL传输】,就能够收到服务端重传的FIN/ACK报文，然后客户端重传依次ACK报文，并重新启动2MSL计时器。如此保证服务端能够正常关闭。
+  防止历史连接中的数据，被后面相投四元组的连接错误的接收
	+ **序列号和初始化序列号并不是无限递增的，会发生回绕为初始值的情况，这意味着无法根据序列号来判断新老数据**
	+ 2MSL时间足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。
	2MSL时长相当于至少运行报文丢失一次


### 谈一谈TCP的流量控制和拥塞控制
首先谈一谈流量控制，在网络传输过程中，发送方发送数据时必须考虑接收方的处理能力，如果一直无脑发送数据给对方，但是对方处理不过来，就会触发重传机制，导致了网络流量的浪费，为了解决这种现象，TCP提供了流量控制的机制，让发送方根据接收方的实际接收能力控制发送的数据量。
流量控制实现的关键就是**滑动窗口**，通过发送方和接收方之间的窗口大小来控制数据的发送速率。发送方会根据接收方返回的确认信息和窗口大小，动态调整发送窗口的大小，以确保网络不会出现拥塞。

流量控制是避免发送方的数据填满接收方的缓存，但是并不知道网络中会发生什么，拥塞控制的目的就是避免发送方的数据填满整个网络。
拥塞控制的关键是通过拥塞窗口，它会根据网络的拥塞程度动态变化，主要是通过拥塞控制的四个算法来实现，包括**慢启动、拥塞避免、拥塞发生，快速恢复**。
具体过程是，刚开始使用慢启动算法，此时拥塞窗口的大小呈指数级增长，当达到慢启动门限时，改为拥塞避免，拥塞窗口为线性增长，当触发超时重传，慢启动门限减为一半，重启开始慢启动，当触发快速重传，慢启动门限设置为当前拥塞窗口的一半，拥塞窗口等于慢启动门限，进入拥塞避免。

### TCP粘包问题

所谓粘包就是连续给对端发送两个或者两个以上的数据包，对端在一次收取中可能收到的数据包大于 1 个，大于 1 个，可能是几个（包括一个）包加上某个包的部分，或者干脆就是几个完整的包在一起。当然，也可能收到的数据只是一个包的部分，这种情况一般也叫**半包**。

无论是半包还是粘包问题，其根源是上文介绍中 TCP 协议是流式数据格式。解决问题的思路还是想办法从收到的数据中把包与包的边界给区分出来。那么如何区分呢？目前主要有三种方法：

+ 固定包长的数据包

  + 顾名思义，即每个协议包的长度都是固定的。举个例子，例如我们可以规定每个协议包的大小是 64 个字节，每次收满 64 个字节，就取出来解析（如果不够，就先存起来）。

  这种通信协议的格式简单但灵活性差。如果包内容不足指定的字节数，剩余的空间需要填充特殊的信息，如 \0（如果不填充特殊内容，如何区分包里面的正常内容与填充信息呢？）；如果包内容超过指定字节数，又得分包分片，需要增加额外处理逻辑——在发送端进行分包分片，在接收端重新组装包片（分包和分片内容在接下来会详细介绍）。

+ 以指定字符（串）为包的结束标志

  + 这种协议包比较常见，即字节流中遇到特殊的符号值时就认为到一个包的末尾了。例如，我们熟悉的 FTP协议，发邮件的 SMTP 协议，一个命令或者一段数据后面加上"\r\n"（即所谓的 **CRLF**）表示一个包的结束。对端收到后，每遇到一个”\r\n“就把之前的数据当做一个数据包。

    这种协议一般用于一些包含各种命令控制的应用中，其不足之处就是如果协议数据包内容部分需要使用包结束标志字符，就需要对这些字符做转码或者转义操作，以免被接收方错误地当成包结束标志而误解析。

+ 包头+包体格式

  + 这种格式的包一般分为两部分，即包头和包体，包头是固定大小的，且包头中必须含有一个字段来说明接下来的包体有多大。

  + ```
    struct msg_header
    {
      int32_t bodySize;
      int32_t cmd;
    };
    ```

# 操作系统

## Windows和Linux内核差异

对于内核的架构一般由三种类型：
+ 宏内核，包含多个模块，整个内核像一个完整的程序
+ 微内核，有一个最小版本的内核，一些模块和服务则由用户态管理
+ 混合内核，是宏内核和微内核的结合体，内核中抽象出了微内核的概念，也就是内核中会有一个小型的内核，其他模块就在这个基础上搭建，整个内核是个完整的程序
Linux的内核设计是采用了宏内核，Window的内核设计则是采用了混合内核
Linux可执行文件格式叫做ELF，Windows可执行文件格式叫做PE。

## 什么是中断

在计算机中，中断是系统用来响应硬件设备请求的一种机制，操作系统收到硬件的中断请求，会打断正在执行的进程，然后调用内核中的中断处理程序来响应请求。

中断是一种异步的事件处理机制，可以提高系统的并发处理能力

操作系统收到了中断请求，会打断其他进程的运行，所以**中断请求的响应程序，也就是中断处理程序，要尽可能快的执行完，这样可以减少对正常进程运行调度地影响。**

而且，中断处理程序在响应中断时，可能还会「临时关闭中断」，这意味着，如果当前中断处理程序没有执行完之前，系统中其他的中断请求都无法被响应，也就说中断有可能会丢失，所以中断处理程序要短且快。

### 什么是软中断？

那 Linux 系统**为了解决中断处理程序执行过长和中断丢失的问题，将中断过程分成了两个阶段，分别是「上半部和下半部分」**。

- **上半部用来快速处理中断**，一般会暂时关闭中断请求，主要负责处理跟硬件紧密相关或者时间敏感的事情。
- **下半部用来延迟处理上半部未完成的工作**，一般以「内核线程」的方式运行。

网卡收到网络包后，通过 DMA 方式将接收到的数据写入内存，接着会通过**硬件中断**通知内核有新的数据到了，于是内核就会调用对应的中断处理程序来处理该事件，这个事件的处理也是会分成上半部和下半部。

上部分要做的事情很少，会先禁止网卡中断，避免频繁硬中断，而降低内核的工作效率。接着，内核会触发一个**软中断**，把一些处理比较耗时且复杂的事情，交给「软中断处理程序」去做，也就是中断的下半部，其主要是需要从内存中找到网络数据，再按照网络协议栈，对网络数据进行逐层解析和处理，最后把数据送给应用程序。

所以，中断处理程序的上部分和下半部可以理解为：

- **上半部直接处理硬件请求，也就是硬中断**，主要是负责耗时短的工作，特点是快速执行；
- **下半部是由内核触发，也就说软中断**，主要是负责上半部未完成的工作，通常都是耗时比较长的事情，特点是延迟执行；

还有一个区别，硬中断（上半部）是会打断 CPU 正在执行的任务，然后立即执行中断处理程序，而软中断（下半部）是以内核线程的方式执行，并且每一个 CPU 都对应一个软中断内核线程，名字通常为「ksoftirqd/CPU 编号」，比如 0 号 CPU 对应的软中断内核线程的名字是 `ksoftirqd/0`

不过，软中断不只是包括硬件设备中断处理程序的下半部，一些内核自定义事件也属于软中断，比如内核调度等、RCU 锁（内核里常用的一种锁）等。

## 键盘敲入字母时，发送了什么
+ 键盘控制器产生扫描码数据，将其缓冲在【键盘控制器的寄存器】中，然后键盘控制器通过总线给CPU发送中断请求
+ CPU收到中断请求后，操作系统会【保存被中断进程的上下文】，然后【调用键盘的中断处理程序】
+ 键盘的中断处理程序是在键盘驱动程序初始化时注册的，其功能就是从键盘控制器的寄存器的缓冲区读取扫描码，再根据扫描码找到用户在键盘输入的字符
+ 得到显示字符的ASCII码后，会把ASCII码放到【读缓冲区队列】，显示设备的驱动程序会定时从【读缓冲区队列】读取数据放到【写缓冲区队列】，最后把【写缓冲区队列】的数据一个一个写入到显示设备控制器的寄存器中的数据缓冲区，最后将这些数据显示到屏幕上
+ 显示出结果后，恢复被中断进程的上下文

## 内核态用户态

### Linux 用户态切换到内核态的 3 种方式

- 系统调用
  + 系统调用是用户进程主动发起的操作。发起系统调用，陷入内核，由操作系统执行系统调用，然后再返回到进程。
  + 系统调用实质上就是函数调用，只不过调用的是系统函数，处于内核态而已。
  + 用户在调用系统调用时会向内核传递一个系统调用号，然后系统调用处理程序通过此号从系统调用表中找到相应的内核函数执行，最后返回。

- 中断

  + 中断包括I/O设备发出的I/O中断、各种定时器引起的时钟中断、调试程序中设置的断点引起的调试中断等。

  + 中断由处理器外部的【硬件】产生，不是执行某条指令的结果，也无法预测发生的时机。

  + 由于中断独立于当前执行的程序，因此中断是异步事件

- 异常
  - 异常包括程序运算引起的各种错误如除0、缓冲区溢出、缺页等。
  - 异常是一种错误情况，是执行当前指令的结果，可能被错误处理程序修正，也可能直接终止应用程序。
  - 异常是同步的


### 用户态到内核态的切换

+ 保留用户态现场（上下文、寄存器、用户栈等）
+ 复制用户态参数，用户栈切到内核栈，进入内核态
+ 额外的检查（因为内核代码对用户不信任）
+ 执行内核态代码
+ 复制内核态代码执行结果，回到用户态
+ 恢复用户态现场（上下文、寄存器、用户栈等）

## 进程管理

### 操作系统是如何进行进程管理的？

首先，我简单说一下进程从创建到终止的大致过程
当某个进程被创建后，操作系统会按照下面步骤对其进行初始化

+ 给新进程分配一个进程ID
+ 分配内存空间
+ 初始化PCB
+ 进入就绪队列
进入就绪队列后，进程的状态就变为就绪态，操作系统会经过某种调度算法，当调度到该进程时，该进程进入运行态，如果进程中有事件需要等待，例如IO操作，则进程进入阻塞态，IO设备可用时进入就绪态，当被调度后，重新进入运行态，进程完成后，进入终止态
在七状态模型中，增加了挂起态，当排队的进程过多，为解决内存占用问题，将一部分内存中的进程交换到磁盘中，这些别交换到磁盘中的进程，会进入挂起状态，可进一步分为就绪/挂起，阻塞/挂起。

### 进程和线程的区别？
+ 首先，进程是资源分配的最小单位，而线程是cpu调度的最小单位
+ 进程都有自己独立的地址空间，每启动一个进程，系统都会为其分配地址空间，建立数据来维护代码段、堆栈段和数据段，线程没有独立的地址空间，它使用相同的地址空间共享数据
+ 线程的创建以及切换的开销，还有占用的资源比进程小
+ 进程间的通信一般需要通过IPC机制来实现，比如信号，管道，信号量，共享内存，消息队列等，而线程间的通信可以通过全局变量来实现，当然线程间的同步方式还包括互斥锁、读写锁、条件变量、信号量等。

### 进程的通信方式
由于每个进程的用户空间是独立的，不能相互访问，这时就需要借助内核空间来实现进程间通信，因为每个进程都是共享一个内核空间。

Linux内核提供了不少进程间的通信方式，其中最简单的方式就是管道，分为【匿名管道】和【命名管道】。

+ **匿名管道**，比如shell命令种的`|`竖线，其是特殊文件只存在于内存，没有存在于文件系统中，**通信的数据是无格式流并且大小受限**，**通信的方式是单向的**，如果要双向通信，需要创建两个管道，**匿名管道只能用于存在父子关系的进程间通信，匿名管道的生命周期随着进程创建而建立，随着进程终止而消失**。
+ **命名管道**突破了匿名管道只能在父子进程间通信的限制，因为使用命名管道前，需要在文件系统创建一个类型为P的设备文件，可以通过该设备文件通信。另外，不管是匿名管道还是命名管道，进行写入的数据都是**先缓存在内核中**，另一个进程读取数据时也是从内核中获取，同时通信数据都是遵循**先进先出**的原则，不支持lseek之类的文件定位操作。

**消息队列克服了管道通信的数据是无格式的字节流的问题**，消息队列实际上是保存在内核中的**消息链表**，消息队列的消息体是可以用户自定义的数据类型，发送数据的时，会被分成一个一个独立的消息体，当然接收数据时，也要于发送方发送的消息体的数据类型保持一致，这样才能保证读取的数据是正确的。消息队列通信的速度不是最及时的，毕竟**每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程**。

**共享内存可以解决消息队列通信中用户态与内核态之间的数据拷贝过程带来的开销**，它直接分配一个共享空间，每个进程都可以直接访问，**不需要陷入内核态或者系统调用**，大大提高了通信速度，是**最高效的进程间通信方式**，**其带来的新问题就是，多进程竞争同个共享资源会造成数据错乱**。

于是，需要**信号量来保护共享资源**，以确保任何时刻只能有一个进程访问共享资源，这种方式就是**互斥访问**。**信号量不仅可以实现访问的互斥性，还可以实现进程间的同步**。信号量其实是一个计数器，表示资源个数，其值可以通过两个原子操作来控制，分别是P操作和V操作。

上面说的进程间的通信，都是常规状态下的工作模式。**对于异常情况下的工作模式，就需要用信号的方式来通知进程。信号是进程通信机制中唯一的异步通信机制**，信号可以在应用进程和内核之间直接交互，内核可以利用信号来通知用户空间的进程发生了哪些系统事件，**信号事件的来源主要有硬件来源和软件来源**，一旦有信号发生，进程有三种方式相应信号：**执行默认操作、捕捉信号、忽略信号**。有两个信号是应用进程无法捕捉和忽略的，即`SIGKILL`和`SIGSTOP`,这是为了方便我们能在任何时候结束或停止某个进程。

前面说的通信机制，都是工作在同一台主机，**如果要与不同主机的进程间通信，那么就需要Socket通信**。Socket 实际上不仅用于不同的主机进程间通信，还可以用于本地主机进程间通信，可根据创建 Socket 的类型不同，分为三种常见的通信方式，一个是基于 TCP 协议的通信方式，一个是基于 UDP 协议的通信方式，一个是本地进程间通信方式。



> 信号量备注

信号量（Semaphore）是一个整型变量，可以对其执行down和up操作，也就是常见的P和V操作。

+ down：如果信号量大于0，执行-1操作；如果信号量等于0，进程睡眠，等待信号量大于0
+ up：对信号量执行+1操作，唤醒睡眠的进程让其完成down操作。

down和up操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。

如果信号量的取值只能为0或者1，那么就成了**互斥量（Mutex）**, 0表示临界区已经加锁，1表示临界区解锁。

```c++
typedef int semaphore;
semaphore mutex = 1;
void P1(){
    down(&mutex);
    //临界区
    up(&mutex);
}

void P2(){
    down(&mutex);
    //临界区
    up(&mutex);
}
```

**使用信号量实现生产者-消费者问题**

```c++
#define N 100
typedef int semphore;
semaphore mutex = 1;
semaphore empty = N;
semaphore full = 0;

void producer(){
    while(true){
        int item = produce_item();
        down(&empty);
        down(&mutex);
        insert_item(item);
        up(&mutex);
        up(&full);
    }
}

void consumer(){
    while(true){
        down(&full);
        down(&mutex);
        int item = remove_item();
        consume_item(item);
        up(&mutex);
        up(&empty);
    }
}
```

### 进程状态的切换

![image-20230328101734045](https://raw.githubusercontent.com/mowang111/image-hosting/master/typora_images/image-20230328101734045.png)

+ 就绪态（ready）：等待被调度
+ 运行态（running）
+ 阻塞态（waiting）：等待资源

注意：

+ 只有就绪态和运行态可以相互转换，其他都是单向转换。就绪状态的进程通过调度算法从而获得CPU时间，转为运行态；而运行态的进程，在分配给它的CPU时间片用完之后就会转为就绪态，等待下一次调度。
+ 阻塞态就是缺少需要的资源从而由运行态转换而来，但是该资源不包括CPU时间，缺少CPU时间会从运行态转为就绪态。



### 进程的调度算法

#### 批处理系统

批处理系统没有太多的用户操作，在该系统中，调度算法目标时保证是保证吞吐量和周转时间（从提交到终止的时间）。

1. 先来先服务 first-come first-serverd（FCFS）

   有利于长作业，不利于短作业

2. 短作业优先 shortest job first（SJF）

   长作业可能会饿死

3. 最短剩余时间优先 shortest remaining time next (SRTN)

   最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。

#### 交互式系统

交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。

1. 时间片轮转

   将所有就绪进程按FCFS的原则排成一个队列，每次调度时，把CPU时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把CPU时间分配给队首进程。

   时间片轮转的效率和时间片的大小有很大的关系：

   + 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
   + 而如果时间片过长，那么实时性就不能得到保证。

2. 优先级调度

   为每个进程分配一个优先级，按优先级进行调度

   为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加进程的优先级。

3. 多级反馈列表

   一个进程需要执行100个时间片，如果采用时间片轮转调度算法，那么需要交换100次。

   多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小不同，例如 1，2，4，8，16，32，64。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换7次。

   每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。

   可以将这种调度算法看成时时间片轮转调度算法和优先级调度算法的结合。

   ![image-20230328104529594](C:\Users\11547\AppData\Roaming\Typora\typora-user-images\image-20230328104529594.png)



#### 实时系统

实时系统要求一个请求在一个确定时间内得到响应。

分为硬实时和软实时，前者必须满足决定的截止时间，后者可以容忍一定的超时。



### 线程的同步方式
互斥锁，读写锁
信号量
条件变量



### 线程的切换

线程切换是指操作系统从一个正在执行的线程切换到另一个线程的过程，以实现多任务并发执行，可以分为以下几个步骤：

1. **保存当前线程上下文**：在进行线程切换前，操作系统会保存当前线程的寄存器和栈等上下文信息，以便在切回该线程时能够恢复它的执行状态。
2. **选择新的线程**：操作系统会根据一定的调度算法从就绪队列中选择一个新的线程执行。调度算法通常会考虑线程的优先级、等待时间、资源需求等因素来决定选择哪个线程。
3. **恢复新线程的上下文**：操作系统会根据选择的新的线程的上下文信息来恢复其执行状态。这个过程包括加载新线程的寄存器和栈等信息，使其可以从上次被挂起的地方继续执行。
4. **更新调度信息**：操作系统会更新线程的状态信息，例如将原来的线程从执行状态变为就绪状态，并将新的线程从就绪状态变为执行状态。
5. **执行新线程**：最后，操作系统会将控制权交给新的线程，让其开始执行。这个过程通常包括更新计时器、记录线程执行时间等操作。

当新线程的时间片用尽或者需要等待某些资源时，操作系统会再次进行线程切换。

### 死锁
死锁是指多个进程循环等待其他进程占有的资源而无限期地僵持下去的局面。当两个或两个以上的进程同时对多个互斥请求使用时，有可能导致死锁

#### 造成死锁的必要条件
1. **互斥条件**。即某个资源在一段时间内只能由一个进程占有，不能同时被两个或者两个以上的进程占有
2. **不可抢占条件**。进程所获得的资源在未使用完毕前，资源申请者不能强行地从资源占有者手中夺取资源，而只能由该资源占有者自行释放
3. **占有且申请条件**。进程至少已占有一个资源，但又申请新的资源；由于该资源已被另外进程占有，此时该进程阻塞；但是它在等待新资源的同时，仍继续占有已有资源。
4. **循环等待条件**。存在一个进程等待序列{P1,P2,P3...Pn}，其中P1等待P2所占有的某一资源，P2等待P3占有的某一资源...，而Pn等待P1所占有的某一资源，形成一个进程循环等待环

#### 死锁预防
死锁预防是保证系统不进入死锁的一种策略，基本思想是要求进程申请资源时遵循某种协议，从而打破产生死锁的必要条件中的一个或几个，保证系统不进入死锁状态。
1. 打破互斥条件。即允许进程同时访问某些资源
2. 打破不可抢占条件。即允许进程强行从占有者那里夺取某些资源，就是说当一个进程已经占有了某些资源，而又申请新的资源，但又不能被立即满足时，它必须释放所占有的全部资源，以后再重新申请。它所释放的资源可以分配给其他进程，这就相当于该进程占有的资源被隐蔽地抢占了。该方法实现困难，会降低系统性能
3. 打破占有且申请条件。可以实行资源预先分配的策略，即进程再【运行前一次性向系统申请它所需要的全部资源】，如果某个进程所需要的全部资源得不到满足，则不分配资源，此进程暂不运行。
4. 打破循环等待条件，实行资源有序分配策略，即把资源事先编号，按号分配。所有进程对资源的请求必须严格按资源序号递增的顺序提出，进程占用了小号资源，才能申请大号资源，就不会产生环路

## 内存管理

### 操作系统保护模式和实模式的区别

+ 实模式将整个物理内存看成分段的区域，程序代码和数据位于不同区域，系统程序和用户程序并没有区别对待，而且每一个指针都是指向实际的物理地址。这样一来，用户程序的一个指针如果指向了系统程序区域或者其他用户程序区域，并修改了内容，那么对于这个被修改的系统程序或者用户程序，其后果就是灾难性的。再者，随着软件的发展，1M的寻址空间已经远远不能满足实际的需求了。最好，对处理器的多任务支持需求也日益紧迫，所有这些都促使新技术的出现。
+ 为了克服实模式下的内存非法访问的问题，并满足内存寻址和多任务需求，处理器厂商开发出保护模式。在保护模式中，除了内存寻址空间大大提高；提供了硬件对多任务的支持；物理内存地址也不能直接被程序访问，程序内部的地址（虚拟地址）要由操作系统转化为物理地址去访问，程序对此一无所知。至此，进程（程序的运行态）有了严格的边界，任何其他进程根本没有版本访问不属于自己的物理内存区域，甚至在自己的虚拟地址范围内也不是可以任意访问的，因为由一些虚拟区域已经被放进一些公共系统运行库。这些区域也不能随便修改，若修改就会有出现Linux中的段错误，或者Windows中的非法内存访问对话框。

### 虚拟内存的内存布局

![image-20230323222108264](https://raw.githubusercontent.com/mowang111/image-hosting/master/typora_images/image-20230323222108264.png)

由低到高分别是6种不同的内存段：

+ 代码段，包括二进制可执行代码
+ 数据段，包括已初始化的静态常量和全局变量
+ BSS段，包括未初始化的静态变量和全局变量
+ 堆段，包括动态分配的内存，从低地址开始向上增长
+ 文件映射段，包括动态库、共享内存，从低地址开始向上增长。
+ 栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是8MB。当然系统也提供了参数，以便我们自定义大小。

# 数据库

## MySQL索引
MySQL中的索引分为三类：B+树索引、Hash索引、全文索引

### MySQL为什么使用B+树作为索引？

要设计一个MySQL的索引数据结构，不仅要考虑数据结构增删改的时间复杂度，更重要的是要考虑磁盘I/O的操作次数。因为索引和记录都是存放再硬盘，硬盘是个非常慢的存储设备，我们在查询数据的时候，最好能在尽可能少的磁盘I/O的操作次数内完成。

二分查找树虽然是一个天然的二分结构，能很好的利用二分查找快速定位数据，但是它存在一种极端情况，每当插入的元素都是属内的最大元素，就会导致二分查找树退化成一个链表，此时查询复杂度就会从O(logn)降低为O(n)。

为了解决二分查找树退化成链表的问题，就出现了自平衡二叉树，保证了查询操作的时间复杂度维持在O(logn)。但是它本质上还是一个二叉树，每个节点只能有2个子节点，随着元素的增多，树的高度就越来越高。

而树的高度决定于磁盘I/O操作的次数，因为树是存储在磁盘中的，访问每个节点，都对应一次磁盘I/O操作，也就是说树的高度就等于每次查询数据时磁盘I/O操作的次数，所以树的高度越高，就会影响查询性能。

B树和B+树都是通过多叉树的方式，会将树的高度变矮，所以这两个数据结构非常适合检索存于磁盘中的数据。

但是MySQL默认的存储引擎InnoDB采用的是B+作为索引的数据结构，原因有：

+ B+树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比存放既存索引又存记录的B树，B+树的非叶子节点可以存放更多的索引，因此B+树可以比B树更矮胖，查询底层节点的磁盘I/O次数会更少。
+ B+树有大量的冗余节点（所有非叶子节点都是冗余索引），这些冗余索引让B+树在插入、删除的效率都比较高，比如删除根节点的时候，不会像B树那样发生复杂的树的变化。
+ B+树叶子节点之间用链表连接了起来，有利于范围查询，而B树要实现范围查询，只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘I/O操作，范围查找效率不如B+树。



### B+树
+ 叶子节点存放所有数据，而非叶子节点只存储索引
+ 每个叶子节点存放一页的记录，页与页之间按照顺序排成一个双向链表，页内记录按照顺序排成单向链表

## 事务
事务：一组逻辑处理单元，使数据从一种状态变换到另一种状态。
事务处理的原则：保证所有事务都作为一个工作单元来执行，即使出现了故障，都不能改变这种执行方式。当在一个事务中执行多个操作时，要么所有的事务都被提交，那么这些修改就永久地保存下来，要么数据库管理系统将放弃所作的所有修改，整个事务回滚到最初状态。
事务的ACID特性：
+ 原子性（atomicity）
	+ 事务的所有操作都是一个整体
+ 一致性（consistency）
	+ 一致性是指事务执行前后，数据从一个合法状态变换到另一个合法状态，这种状态是语义上的而不是语法上的，跟具体业务有关。
+ 隔离性（isolation）
	+ 事务的隔离性是指一个事务的执行不能被其他事务干扰，即一个事务内部的操作和使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能相互干扰。
	+ 事务的隔离性由【锁机制】实现
+ 持久性（durability）
	+ 事务一旦提交，它对数据库中的数据的改变就是永久性的
	+ 持久性是通过事务日志来保证的。日志包括了重做日志（redo）日志和回滚日志。当我们通过事务对数据进行修改时，首先会将数据库的变化信息记录在重做日志中，然会再对数据库中的对应行进行修改。
+ 事务的原子性、一致性和持久性由事务的redo日志和undo日志来保证
	+ redolog，提供再写入操作，恢复提交事务修改的页操作，用来保证事务的持久性
	+ undolog，回滚行记录到某个特定版本，用来保证事务的原子性、一致性

### 数据并发问题
1. 脏写
	如果事务Session A修改了另一个未提交的Session B修改过的数据，就意味着发生了脏写
2. 脏读
	如果Session A读取了已经被Session B更新但还没有被提交的字段
3. 不可重复读
	Session A读取了一个字段，然后Session B更新了该字段，之后Session A再次读取了同一个字段，值就不同了
4. 幻读
	Session A从一个表中读取了一个字段，然后Session B在该表中插入了一个新的行，之后，如果Session A再次读取同一个表，就会多出几行，意味着发生了幻读

### 事务隔离级别
数据库的隔离级别有四个，由低到高依次为：Read uncommitted、Read committed、Repeatable read、Serializble，这四个级别分别解决脏写、脏读、不可重复读、幻读这几类问题。
+ Read uncommitted（读未提交）：这是最低的隔离级别，允许读取未提交的数据，它可能导致脏读、不可重复读和幻读
+ Read committed（读已提交）：禁止读取未提交的数据。它可以避免脏读，但仍然可能导致不可重复读和幻读。
+ Repeatable read（可重复读）：禁止读取已提交的数据的修改。它可以避免脏读和不可重复读，但仍然可能导致幻读。
+ Serializable（串行化）：这是最高的隔离级别，禁止读取已提交的数据的修改和插入。它可以避免脏读、不可重复读和幻读。

### 并发问题的解决方案
如何解决脏读、不可重复读、幻读这些问题：
+ 方案一：读操作利用多版本并发控制（MVCC），写操作进行加锁
	+ MVCC，就是生成一个ReadView，通过ReadView找到符合条件的记录版本（历史版本由undo日志构建）。查询语句只能读到在生成Readview之前已提交事务所做的更改，在生成ReadView之前未提交的事务或者之后再开启的事务所作的更改时看不到的。而写操作肯定是针对最新版本的记录，读记录的历史版本和改动记录的最新版本本身并不冲突，也就是采用MVCC时，读-写操作并不冲突
	+ 普通的SELECT语句在READ COMMITTED和REPEATALE READ隔离级别下会使用到MVCC读取记录
		+ 在READ COMMITTED隔离级别下，一个事务在执行过程中每次执行SELECT操作时都会生成一个ReadView，ReadView的存在本身就保证了事务不可以读到未提交的事务所作的更改，也就避免了脏读的现象
		+ 在REPEATABLE READ隔离级别下，一个事务在执行过程中只有第一次执行SELECT操作才会生成一个ReadView，之后的SELECT操作都复用这个ReadView，这样就比避免了不可重复读和幻读的问题
+ 方案二：读和写操作都用加锁
	+ 显然可以解决脏读和不可重复读的问题
	+ 幻读的问题的产生是因为当前事务读取了一个范围的记录，然后另外的事务向该范围内插入了新记录，当前事务再次读取该范围的记录时发现了新插入的新记录，采用加锁的方式解决幻读的问题就有点麻烦，因为当前事务在第一次读取记录的时候幻影记录并不存在，所以读取时不知道怎么加锁。
+ 对比
	+ 采用MVCC方式的话，读-写操作并不冲突，性能更高
	+ 采用加锁方式的话，读-写操作彼此需要排队执行，影响性能

## 锁
### 锁的分类
按照对数据的操作类型划分，分为读锁/共享锁，写锁/排他锁
按照对锁的粒度划分，分为表级锁、页级锁、行级锁
+ 表级锁又包括了表级别的读写锁，意向锁，自增锁，元数据锁
+ 行级锁又包括了记录锁，间隙锁，临建锁，插入意向锁
按照对待锁的态度划分，分为悲观锁和乐观锁
按照加锁方式划分，分为隐式锁和显示锁

## MVCC
MVCC，多版本并发控制，是通过数据行的多个版本管理来实现数据库的并发控制，这项技术使得InnoDB的事务隔离级别下执行【一致性读】操作有了保证。换言之，就是为了查询一些正在被另一个事务更新的行，并且可以看到他们被更新之前的值，这样在做查询的时候就不用等待另一个事务释放锁了。

### MVCC的实现原理
MVCC实现依赖于：隐藏字段、Undo log、Read View
#### 隐藏字段、Undo log版本链
+ trx_id：每次一个事务对某条聚簇索引记录进行改动时，都会把该事务的事务id赋值给trx_id隐藏列。
+ roll_pointer：每次对某条聚簇索引记录进行改动时，都会把旧的版本写入到undo日志中，然后这个隐藏列就相当于一个指针，可以通过它来找到该记录修改前的值
每次对记录进行改动，都会记录一条undo日志，每条undo日志都有一个roll_pointer属性（INSERT操作对应日志没有该属性，因为该记录没有更早的版本），将这些undo日志都连起来，串成一个链表：
![image.png](https://raw.githubusercontent.com/mowang111/image-hosting/master/typora_images/20230226211117.png)

#### ReadView
ReadView就是事务再使用MVCC机制进行快照读操作时产生了读视图。当事务启动时，会生成数据库系统当前的一个快照，InnoDB为每个事务构造了一个数字，用来记录并维护系统当前活跃事务的ID。

#### 设计思路
使用【读未提交】隔离级别的事务，由于可以读到未提交事务修改过的记录，所以直接读取记录的最新版本就好。
使用【串行化】隔离级别的事务，InnoDB规定必须使用加锁的方式来记录
使用【读已提交】和【可重复读】隔离级别的事务，就必须保证读到已经提交了的事务修改过的记录。如果另一个事务已经修改了记录但是尚未提交，是不能直接读取到最新版本的记录的，核心问题就是【需要判断一下版本链中哪个版本是当前事务可见的】，这是ReadView需要解决的问题。
ReadView包含了4个主要的内容：创建ReadView的事务ID，生成ReadView时当前系统中活跃的读写事务id表，活跃事务中最小的事务ID以及当前系统应该分配给下一个事务的id。
从undo版本链中从新到旧寻找当前事务可访问的版本，如果版本的事务id和ReadView的事务id相同，就说明是当前事务的版本，可以访问，否则如果事务id小于ReadView中活跃事务中的最小id，说明已提交可以访问，如果大于等于当前系统应该分配给下一个事务的id，就说明当前事务在ReadView生成后才开启，不能访问，如果处于两者之间，就判断是否在活跃列表，不在则可以访问，在则不能访问。

# 网络模型

## 阻塞IO，非阻塞IO, 同步IO，异步IO

以read读取网络接受包为例，首先将网络数据包接收阶段分为两个阶段：

+ 数据准备阶段：这个阶段，网络数据包到达网卡，通过DMA的方式将数据包拷贝到内存中，再经过硬中断，软中断，以及经过内核线程通过内核协议栈处理，最终数据发送到内核Socket的接收缓冲区。
+ 数据拷贝阶段：在这个阶段，数据已经到达内核Socket的接收缓冲区，此时数据存在于内核空间中，需要将数据拷贝到用户空间。

对于阻塞IO来说，需要等待这两个阶段都完成，比如使用read调用，发现socket接收缓冲区没有数据，就等待数据到来，然后数据拷贝到用户空间之后，执行之后的代码。

对于非阻塞IO来说，当read调用发现socket接收缓冲区没有数据，直接返回错误标志`EWOULDBLOCK`，之后线程不会阻塞，也不会让出CPU，需要不断轮询直到Socket缓冲区中有数据，这时还是需要等待数据拷贝阶段。

以上阻塞IO和非阻塞IO都是同步IO，而异步IO是上面两个阶段都不用等待，全部交由内核处理，内核拷贝完数据后通知进程读用户空间中的数据。



## 零拷贝技术
sendfile系统调用实现了零拷贝技术，零拷贝技术的文件传输方式相比于传统文件传输方式，减少了2次上下文切换和数据拷贝次数，只需要2次上下文切换和数据拷贝次数，就可以完成文件的传输，而且2次的数据拷贝过程，都不需要通过CPU，2次都是由DMA来搬运，使用零拷贝的项目有nginx,kafka。

![image.png](https://raw.githubusercontent.com/mowang111/image-hosting/master/typora_images/20230219121554.png)

![image.png](https://raw.githubusercontent.com/mowang111/image-hosting/master/typora_images/20230319223442.png)

## 线程池的实现

线程池遵循了生产者-消费者模型，通过一个任务队列来实现任务的提交与执行。具体来说，线程池包含一个任务队列和一组工作线程。任务的提交通过向任务队列中添加一个待执行的任务实现，工作线程则通过不断从任务队列中获取任务并执行来完成任务的处理。

由于需要对这个工作队列做互斥访问，需要一个互斥锁，以及通过信号量做线程同步。

具体实现就是在线程池的构造函数中利用`pthread_create`和`pthread_deatch`创建和脱离一定数量的线程，线程调用的函数等待工作队列有数据后，取出并处理数据，另外实现一个向工作队列中添加数据的函数。

```c++
template<typename T>
class threadpool{
public:
	threadpool(int thread_nums = 8, int max_requests = 10000);
	~thread();
	bool append(T* request);
private:
	static void work(void* args);
	void run();
private:
	int m_thread_nums;
	int m_max_requests;
	pthread_t* m_threads;
	std::list<T*> m_workqueue;
	locker m_queuelocker;
	sem m_queuestat;
	bool m_stop;
};

template<typename T>
threadpool<T>::threadpool(int thread_nums, int max_requests)::m_thread_nums(thread_nums), m_max_requests(max_requests){
	if((thread_nums <= 0) || (max_requests <= 0)) throw std::exception();
	m_threads = new pthread_t[thread_nums];
	if(!m_threads) throw std::exception();
	for(int i = 0; i < thread_nums; i++){
		if(pthread_create(m_threads+i, NULL, work, this)!=0){
			delete[] m_threads;
			throw std::expection();
		}
		if(pthread_deatch(m_threads[i])){
			delete[] m_threads;
			throw std::expection();
		}
	}
}

template<typename T>
threadpool<T>::~threadpool(){
	delete[] m_threads;
	m_stop = true;
}

template<typename T>
bool threadpool<T>::append(T* request){
	m_queuelocker.lock();
	if(m_workqueue.size() >= m_max_requests){
		m_queuelocker.unlock();
		return false;
	}
	m_workqueue.push_back(request);
	m_queuelocker.unlock();
	m_queuestat.post();
	return ture;
}

template<typename T>
void* threadpool<T>::work(void* args){
	threadpool* pool = (threadpool*) args;
	pool->run();
	return pool;
}

template<typename T>
void threadpool<T>::run(){
	while(!m_stop){
		m_queuestat.wait();
		m_queuelocker.lock();
		if(m_workqueue.empty()){
			m_queuelocker.unlock();
			continue;
		}
		T* request = m_queue.front();
		m_queue.pop();
		m_queuelocker.unlock();
		if(!request) continue;
		request->process();
	}
}
```

# 设计模式

## 单例模式
### 饿汉模式
```c++
class Singleton{
public:
	static Singleton& getInstance{
		return instance;
	}
	//禁用拷贝构造函数和赋值运算符
	Singleton(const Singleton&) = delete;
	Singleton& operator= (const Single&) = delete;
private:
	static Singleton instance;
	Singleton(){}
	~Singleton(){}
};
Singleton Singleton::instance;
```
注意：饿汉模式存在的隐藏问题，在于非静态对象（函数外的static对象）在不同编译单元中的初始化顺序是未定义的。如果在初始化完成之前调用getInstance()方法会返回一个未定义的实例。

### 懒汉模式
```c++
class Singleton{
public:
	static Singleton& getInstance{
		static Singleton instance;
		return instance;
	}
	Singleton(const Singleton&) = delete;
	Singleton& operator= (const Singleton&) = delete;
private:
	Single(){}
	~Single(){}
};
```

# 针对简历补充

## TinyWebServer
### 介绍一下这个项目
这个项目主要是自己用来学习Linux网络编程的，是一个在Linux中使用C++语言开发的轻量级多线程HTTP服务器，支持一定数量的客户端连接服务器并访问图片视频资源。
首先，客户端需要与服务器建立连接，服务端对连接socket进行监听，当有多个连接请求的时候，服务器需要分配多个逻辑单元来处理不同的客户请求，这时需要用到多线程技术实现并发
客户端与服务端建立连接后，服务端需要处理客户端发送来的HTTP请求报文，于是又需要通过socket监听用户的请求，加上之前需要对连接socket监听，所以服务端需要对多个socket同时监听，这里就用到**epoll这种I/O复用技术**，I/O复用技术虽然可以同时监听多个文件描述符，但是它本身是阻塞的，当有多个文件描述符同时就绪时，程序只能按顺序处理其中就绪的每一个文件描述符，为了提高效率，这里也通过多线程技术实现并发，为每个就绪的文件描述符分配一个线程来处理。
实现多线程并发用到了半同步半反应堆的并发模型以及同步I/O模拟Proactor的事件处理模式。
在收到HTTP请求报文后，Web服务器就需要对报文进行处理，这里就用到了**HTTP状态机解析HTTP报文**，支持解析GET和POST请求。
最后，还涉及到对服务器的一些优化，包括定时器处理非活动连接和日志的实现，使用单例模式实现日志类，通过同步/异步的方式写入日志。其中异步方式是使用阻塞队列实现，使用生产者/消费者的模式对阻塞队列进行操作。


### 介绍一下两种事件处理模式
这里其实涉及了服务器的事件处理模式，服务器程序通常需要处理三类事件：I/O事件，信号以及定时事件。有两种事件处理模式：Reactor和Proactor。
+ Reactor模式：要求主线程（I/O处理单元）只负责监听文件描述符上是否事件发生（可读、可写），若有，则立即通知工作线程（逻辑单元），将socket可读可写事件放入请求队列，交给工作线程处理。
	+ 主从Reactor模式：mainReactor负责监听server socket，用来处理网络IO连接操作，而subReactor主要做和建立起来的socket做数据交互和事件业务处理操作。
+ Proactor模式：将所有的I/O操作都交给主线程和内核来处理（进行读写），工作线程仅负责处理逻辑，如主线程读写完成后，选择一个工作线程来处理客户请求

通常使用同步I/O模型（如epoll_wait）实现Reactor，使用异步I/O（如aio_read和aio_write）实现Proactor。这里项目使用**同步I/O模拟的Proactor**事件处理模式（主线程使用epoll监听socket，然后将读到的数据封装成对象放入工作队列，然后分配给其他线程）。
### Linux有三种I/O复用方式，为什么用epoll？ 
![image.png](https://raw.githubusercontent.com/mowang111/image-hosting/master/typora_images/20230319222248.png)

select实现多路复用的方式是，将已连接的Socket都放到一个文件描述符集合，然后调用select函数将文件描述符集合拷贝到内核里，让内核检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此Socket标记为可读或可写，接着把整个文件描述符集合拷贝回用户态，然后用户态还需要再通过遍历的方法找到可读或可写的Socket,然后再对其处理。
所以select这种方式，需要进行2次遍历文件描述符集合，一次是在内核态，一次是在用户态，而且还会发生2次拷贝文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间。
select使用固定长度的BitsMap,表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，再Linux系统中，由内核中的FD_SETSIZE限制，默认最大值未1024，只能监听0-1023的文件描述符
poll不再用BitsMap来存储所关注的文件描述符，取而代之用动态数组，以链表的形式来组织，突破了select的文件描述符个数限制，当然还会收到系统文件描述符限制。
但是poll和select并没有太大本质区别，都是使用线性结构存储进程关注的Socket集合，因此都需要遍历用户描述符集合来找到可读或可写的Socket，时间复杂度为O(n)，而且也需要再用户态与内核态之间拷贝文件描述符集合，这种方式随着并发数上来，性能损耗也会呈指数级增长。
epoll通过两个方面解决了select/poll的问题
+ epoll在内核里使用【红黑树】来关注进程所有待检测的Socket，红黑树是个高效的数据结构，增删改一般的时间复杂度是O(n)，通过对红黑树的管理，不需要像select/poll在每次操作时都传入整个Socket集合，减少了内核和用户空间大量的数据拷贝和内存分配
+ epoll使用事件驱动机制，内核里维护了一个【链表】来记录就绪的事件，只将由事件发生的Socket集合传递给应用程序，不需要像select/poll那样轮询扫描整个集合，大大提高了检测效率。

### epoll具体工作流程
1. 通过epoll_create创建epoll对象，此时epoll对象的内核结构包含就绪链表和红黑树，就绪队列用于保存所有读写事件到来的socket，红黑树用于保存所有待检测的socket。
2. 通过epoll_ctl将待检测的socket，加入到红黑树中，并注册一个事件回调函数，当由事件到来之后，回调用这个回调函数，进而通知到epoll对象。
3. 调用epoll_wait等待事件的发生，当内核检测到事件发生后，调用该socket注册的回调函数，执行回调函数就能找到socket对应的epoll对象，然后会将事件加入到epoll对象的就绪队列中，最后将就绪队列返回给应用层。

## HTTP状态机解析HTTP报文？
从状态机负责读取报文的一行，主状态机负责对改行数据进行解析，主状态机内部调用从状态机，从状态机驱动主状态机。
主状态机

+ CHECK_STATE_REQUESTLINE, 解析请求行
+ CHECK_STATE_HEADER，解析请求头
+ CHECK_STATE_CONTENT，解析消息体，仅用于解析POST请求
从状态机
+ LINE_OK，完整读取一行
+ LINE_BAD，报文语法有误
+ LINE_OPEN，读取的行不完整

## 项目如何处理非活动连接的？

本项目中，服务器主循环为每一个连接创建一个定时器，并对每个连接进行定时。另外，利用升序时间链表容器将所有定时器串联起来，若主循环接收到定时通知，则在链表中依次执行定时任务。

本项目的定时方法使用SIGALRM信号，利用alarm函数周期性触发SIGALRM信号，信号处理函数利用管道通知主循环（这里的管道是为了统一事件源），主循环接收到该信号后对升序链表上所有定时器进行处理，若该段时间没有交换数据，则将该连接关闭，释放所占用的资源。

> 统一事件源，是将信号事件与其他事件一样被处理。
> 具体的，信号处理函数使用管道将信号传递给主循环，信号处理函数往管道的写端写入信号值，主循环则从管道的读端读出信号值，使用I/O复用系统调用来监听管道读端的可读事件，这样信号事件与其他文件描述符都可以通过epoll来监测，从而实现统一处理。

## 压力测试

在关闭日志后，使用Webbench对服务器进行压力测试，对listenfd和connfd分别采用ET和LT模式，均可实现上万的并发连接，下面列出的是两者组合后的测试结果.

+ Proactor，LT + LT，93251 QPS
+ Proactor，LT + ET，97459 QPS
+ Proactor，ET + LT，80498 QPS
+ Proactor，ET + ET，92167 QPS
+ Reactor，LT + ET，69175 QPS

Webbench 的原理是通过在本地主机上创建多个客户端连接，对目标服务器发送 HTTP 请求，并记录相应的响应时间和状态码等信息。Webbench 支持多种 HTTP 请求方法、多种文件类型和不同的请求参数，可以根据实际需求进行定制化配置。

## 绞线生产工业一体机
### 介绍一下这个项目
这个项目是一个绞线工厂的工业一体机项目，每台绞线机配备一台一体机，用于生产流程控制和数据采集管理。
一方面，生产流程控制上，一体机主要是工人使用，需要实现打卡签到，查看生产任务以及任务需要的工艺卡信息，打印产品标签，并完成对生产任务的状态控制等功能，此外，为了便于故障排查，增加网络状态显示，以及网络ip修改的功能。另一方面，数据采集管理上，需要采集生产机器的信息，比如生产长度，便于后台统计生产信息，结算工人工资。 
整个一体机主要包括Linux开发板，大彩屏幕以及打印机，RFID刷卡器等外设，程序方面分为两个部分，一个负责生产流程 控制，一个负责数据采集。
生产流程控制的程序，采用多线程技术，分别处理与屏幕等多个外设以及后台的通信，为每个通信设置一个收发工作队列，存储收发的数据，实现功能解耦。
数据采集程序，使用modbus协议定时采集生产机器上的数据，并发送给后台。 最终将程序部署到一百多台一体机上，完成到现在仍正常运行。
### modbus协议
Modbus协议采用主从通信模式（即Master/Slave通信模式），其具有多个变种，包括支持串口（RS-485、RS-232总线），以太网多个版本，最著名的是Modbus RTU, Modbus ASCII和Modbus TCP三种，其中Modbus RTU和Modbus ASCII均为支持RS-485总线的通信协议。
Modbus RTU由于采用二进制表现形式以及紧凑数据结构，通信效率较高，应用比较广泛。
Modbus ASCII由于采用ASCII码传输，并且利用特殊字符作为其字节的开始和结束标识，其传输效率远远低于Modbus RTU协议
Modbus TCP则是在RTU协议上加一个MBAP报头文，依靠TCP的可靠连接服务，在以太网中通信。

### mqtt协议
MQTT是一种基于发布/订阅模式的轻量级消息传输协议。

#### MQTT与HTTP协议对比
+ MQTT的最小报文仅为2个字节，比HTTP占用更少的网络开销
+ MQTT与HTTP都能使用TCP连接，并实现稳定、可靠的网络连接
+ MQTT基于发布订阅模型，HTTP基于请求响应，因此MQTT支持双工通信。
+ MQTT可实时推送消息，但HTTP需要通过轮询获取数据更新。
+ MQTT是有状态的，但是HTTP是无状态的。
+ MQTT可从连接异常断开中恢复，HTTP无法实现此目标