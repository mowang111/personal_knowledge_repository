## GAN

### 论文Generative Adversarial Nets

#### 引言

通过对抗网络建立一个生成模型

训练两个模型：生成器G产生数据分布，辨别器D判断sample是否是真实的，输出的数字表示判断是否为真实的概率。

其中G和D可以都使用多层感知器模型，所以整个系统可以使用反向传播来训练，而不需要<font color='red'>马尔科夫链</font>或者<font color='red'>近似推断</font>对分布进行复杂的采样，所以在计算上有优势

#### 相关工作

之前的工作一直是想直接构建含有特定参数的分布函数的模型，这样的模型可以通过最大化对数似然函数来训练

1. the deep Boltzmann machine 计算上困难
2. generative machines 
3. VAES
4. NCE 使用的损失函数相对复杂
5. predictability minimization
6. Adversatial examples

#### 对抗网络

对抗网络最简单的使用就是生成器和判别器都是MLP

1. learn the generator's distribution
   1. define a prior on input noise variables $p_z(z)$
   2. $G(z;θ_g)$

2. $D(x;θ_d)$来判断x是来自真实采样的数据还是生成器生成的数据，训练的时候给一个标号，真实采样为1，生成器生成为0
3. 训练D的同时也训练G，G来最小化$log(1-D(G(z)))$
   1. 辨别器很好的情况下，该项为0

![image-20220304141446829](https://raw.githubusercontent.com/mowang111/image-hosting/master/typora_images/image-20220304141446829.png)

+ D是完美的情况下，该式两个加和项都是0，而如果D（x）大于0小于1时，两者都是负值，所以，两个加和也是负值，所以想让D更好，就要让V这个值越大
+ G主要是第二项，要使生成器更好，就要骗过辨别器，所以尽量让D(G(z))为1，1-D(G(z))就是0，再加上log就是负无穷，所以想让G更好，就要V这个值越小
+ 这是两人的minmax游戏，最后达到纳什均衡

![image-20220304185448145](https://raw.githubusercontent.com/mowang111/image-hosting/master/typora_images/image-20220304185448145.png)

> 黑色的线表示真实采样的x分布，绿色的表示生成器生成的x分布，蓝色的表示辨别器判断的值

### 算法

![image-20220304185825483](https://raw.githubusercontent.com/mowang111/image-hosting/master/typora_images/image-20220304185825483.png)

> 首先训练生成器，输入噪音z和真实数据x，将这个放进价值函数里求梯度，对辨别器的参数求梯度，更新辨别器，然后做k步，接着取得m个噪音样本，对生成器进行训练，将第二项对生成器的参数求梯度，再更新生成器，至此完成一次迭代

> 问题1：k不能取太小，也不能取太大，取太小，辨别器基本不能辨别，意义不大，取太大，第二项训练的时候接近0，再求导，在生成模型上的更新会有困难

> 问题2：如何判断收敛

### 理论上的结果

1. 目标函数有一个全局最优解，当前仅当生成器学到的分布和真实分布相等。（目标函数正确）

   1. ![image-20220304191050701](https://raw.githubusercontent.com/mowang111/image-hosting/master/typora_images/image-20220304191050701.png)

   2. x是由z通过g生成出来的，x=g(z)![image-20220304191305051](https://raw.githubusercontent.com/mowang111/image-hosting/master/typora_images/image-20220304191305051.png)

      求导求最大值，可得D(x)->proposition  1

      

      可以转换成两个KL散度

      ![image-20220304191328310](https://raw.githubusercontent.com/mowang111/image-hosting/master/typora_images/image-20220304191328310.png)

      ![image-20220304192126274](https://raw.githubusercontent.com/mowang111/image-hosting/master/typora_images/image-20220304192126274.png)

      KL是大于等于0的，当KL取到0时，两个分布相等

      ![image-20220304192328263](https://raw.githubusercontent.com/mowang111/image-hosting/master/typora_images/image-20220304192328263.png)

      也可以表示成JS散度

2. 算法确实可以求解目标函数

   1. ![image-20220304192455364](https://raw.githubusercontent.com/mowang111/image-hosting/master/typora_images/image-20220304192455364.png)
   2. 我们首先是允许算法1中间D每一步都达到最优解（虽然但是，没有允许D每一步都达到最优解），如果对G的优化是执行上面这个步骤，$p_g$会收敛到$p_{data}$
   3. 证明是将$V(G,D)=U(p_g,D)$,展开之后是一个关于$p_g$的凸函数，然后做梯度下降的时候就会得到最优解。

## CGAN

### 论文背景

传统的对抗网络被引入到训练生成模型中，用生成器（Generator）随机生成噪点，判别器（Discriminator）判断判断生成图像真假，两者相互对抗，最终生成器生成判别器无法判断真假的图片。

但是这种对抗网络对生成数据的模式没有控制，如果可以加上一些条件信息，便可以指导数据的生成过程，<font color='red'>比如给定很多不同种类的狗的图片，传统对抗网络只能生成一只狗，但是不能控制狗的种类，如果想要控制输出的内容，比如可以输入一段文字“dog is running”，控制输出的图片，就会生成奔跑的狗的图片</font>

![Reasons Parasite Prevention Is Necessary for Dogs | Forever Vets](https://raw.githubusercontent.com/mowang111/image-hosting/master/typora_images/Forever-Vets-Animal-Hospital_Reasons-Parasite-Prevention-Is-Necessary-for-Dogs_IMAGE1.jpeg)

论文的主要工作就是输入类别的标签，产生相对应的图片

### 相关工作

虽然很多监督学习也取得了很大的成功，但是在处理大量的输出种类时还是会具有很大的挑战，另一个问题是，至今为止大部分的工作都着眼于输入输出一对一的映射，然而现实中很多有趣的问题，都是一对多的映射。

### Conditional Adversarial Nets

![image-20220304200428134](https://raw.githubusercontent.com/mowang111/image-hosting/master/typora_images/image-20220304200428134.png)

![image-20220304200437357](https://raw.githubusercontent.com/mowang111/image-hosting/master/typora_images/image-20220304200437357.png)

![image-20220302205722862](https://raw.githubusercontent.com/mowang111/image-hosting/master/typora_images/image-20220302205722862.png)

### 实验结果

#### Unimodal

##### 生成器

噪声z（100维服从均匀分布的噪声向量）和额外信息y分别映射到隐藏层（200和1000unit），使用Relu的激活函数，在被第二次映射前，链接所有的1200个unit,最终有一个Sigmoid激活函数的层输出784维（28*28）的单通道图像

##### 鉴别器

将x（输入图像）映射到**具有240units和5 pieces的maxout层**，y（类别标签的one hot编码）映射到**具有50 units和5 pieces的maxout层**，在喂给下一个sigmoid层之前，两个maxout层**连在一起为一个240units和4pieces的maxout层**,最终输出为x为来自训练集（真实图像）的概率

#### Multimodal

Flickr这些标签图片的网站，他们的图片标签都是用户定义的，没有一般的标签那么规范，更像是接近自然语言的描述，Conceptual word embeddings可以用来将这些自然语言标准化

这次实验就自动为图片加标签，使用条件对抗网络产生一个或多个标签向量

在ImageNet数据集(21000labels)上预训练模型，采用最后一层全连接（4096 units）输出作为图像特征

文本表示是选取YFCC数据集，预处理后用skip-gram model训练成200维的词向量，除去出现次数少于200的词，最后剩下247465个词。

图片使用MIR Flickr 25,000数据集，用convolutional和language模型提取图片和标签，没有标签的图片会被剔除，注释会被当成额外的标签，150000个样本被当作训练集，有多个标签的图片挥别重复放入训练集

为了估计，为每张图片生成100个样例，找到前20个最接近的词汇（using cosine similarity of vector representation of the words in the vocabulary to each sample），再从100个样例中找到十个最常见的词汇。

最有效的生成模型接收100维的高斯噪声，将其映射到500维的ReLu层，映射9600维的图片特征向量到2000维的ReLu隐藏层，这些层最终一起映射到一个200维的线性层，输出单词向量。

辨别器模型包括500和1200维的ReLu隐藏层分别对应于单词向量和图片特征，一个1000units和3 pieces的maxout层，作为join layer ，最终喂给一个单个的sigmoid unit

这个模型用随机梯度下降训练，batch size为100，初始学习率为0.1，随着decay 降到1.00004，学习率也降到0.000001，同时[动量](https://www.jiqizhixin.com/articles/2017-07-01-4)从0.5增长到了0.7

架构和参数选择是使用随机网格搜索和人工选择来交叉确认
