## 卷积神经网络-CNN 的基本原理

卷积层负责提取图像中的局部特征；池化层用来大幅降低参数量级(降维)；全连接层类似传统神经网络的部分，用来输出想要的结果。

![典型的 CNN 由3个部分构成](https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-06-24-cnnjiegou.png)

### 卷积——提取特征

卷积层的运算过程如下图，用一个卷积核扫完整张图片：

![卷积层运算过程](https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-06-19-juanji.gif)

这个过程我们可以理解为我们使用一个过滤器（卷积核）来过滤图像的各个小区域，从而得到这些小区域的特征值。

在具体应用中，往往有多个卷积核，可以认为，每个卷积核代表了一种图像模式，如果某个图像块与此卷积核卷积出的值大，则认为此图像块十分接近于此卷积核。如果我们设计了6个卷积核，可以理解：我们认为这个图像上有6种底层纹理模式，也就是我们用6中基础模式就能描绘出一副图像。以下就是25种不同的卷积核的示例：

![25种不同的卷积核](https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-06-19-150926.jpg)

**总结：卷积层的通过卷积核的过滤提取出图片中局部的特征，跟上面提到的人类视觉的特征提取类似。**

 

### 池化层（下采样）——数据降维，避免过拟合

池化层简单说就是下采样，他可以大大降低数据的维度。其过程如下：

![池化层过程](https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-06-19-chihua.gif)

上图中，我们可以看到，原始图片是20×20的，我们对其进行下采样，采样窗口为10×10，最终将其下采样成为一个2×2大小的特征图。

之所以这么做的原因，是因为即使做完了卷积，图像仍然很大（因为卷积核比较小），所以为了降低数据维度，就进行下采样。

**总结：池化层相比卷积层可以更有效的降低数据维度，这么做不但可以大大减少运算量，还可以有效的避免过拟合。**

 

### 全连接层——输出结果

这个部分就是最后一步了，经过卷积层和池化层处理过的数据输入到全连接层，得到最终想要的结果。

经过卷积层和池化层降维过的数据，全连接层才能”跑得动”，不然数据量太大，计算成本高，效率低下。

![全连接层](https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-06-19-quanlianjie.png)

典型的 CNN 并非只是上面提到的3层结构，而是多层结构，例如 LeNet-5 的结构就如下图所示：

**卷积层 – 池化层- 卷积层 – 池化层 – 卷积层 – 全连接层**

**![LeNet-5网络结构](https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-06-19-lenet.png)**

