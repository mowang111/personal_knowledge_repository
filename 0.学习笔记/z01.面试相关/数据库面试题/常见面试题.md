# 执行一条select/update语句，在MySQL中发生了什么？
![image.png](https://raw.githubusercontent.com/mowang111/image-hosting/master/typora_images/20230301223352.png)
+ Server 层负责建立连接、分析和执行SQL。MySQL大多数的核心功能模块都在这里实现，主要包括连接器，查询缓存（8.0版本去除，因为每次更新都会清空该表缓存，缓存作用较低）、解析器、预处理器、优化器、执行器等，另外，所有的内置函数（如日期、时间、数学和加密函数等）和所有跨存储引擎的功能（如存储过程、触发器、视图等）都在Server层实现。
+ 存储引擎层负责数据的存储和提取。支持InnoDB、MyISAM、Memory等多个存储引擎，不通的存储引擎共用一个Server层。从MySQL5.5版本开始，InnoDB成为MySQL的默认存储引擎。索引数据结构就是由存储引擎层实现的，不同的存储引擎支持的索引类型也不相同，比如InnoDB支持的索引类型是B+树。

执行流程：
1. 连接MySQL：TCP三次握手——连接验证用户名和密码——连接器获取用户权限，然后后面的权限逻辑判断都基于此时读到的权限（管理员中途修改用户权限重启后该用户生效）【使用show processlist查看MySQL服务器被多少个客户端连接】
2. 查询缓存：若有则直接返回数据
3. 解析SQL：首先是【词法分析】。根据数据的字符串识别出关键字，构建出SQL语法树，这样方便后面模块获取SQL类型、表名、字段名、where条件等等。之后是【语法分析】，语法解析器会根据语法规则，判断这个SQL语句是否满足MySQL语法。
4. 执行SQL：首先是预处理阶段，【预处理器】检查SQL查询语句中的表或者字段是否存在，并将`select *` 中的 `*` 符号，扩展为表上的所有列；然后【优化器】主要负责将SQL查询语句的执行方案确定下来，比如在表里面有多个索引的时候，优化器会基于查询成本的考虑，来决定选择使用哪个索引。最后【执行器】就会和存储引擎交互了，交互是以记录为单位的，每查询到一条记录则返回给客户端，再接着查下一条记录。而**对于update，需要先写入redo log缓冲区中，然后再写入undo数据页中，事务提交之后写入binlog日志缓存区内，所有缓存区会在合适时间进行磁盘写入。**

# 三大范式
第一范式（确保每列保持原子性）
如果数据库表中的所有字段值都是不可分解的原子值，就说明该数据库表满足了第一范式。1NF是关系型数据库最基本的条件，否则不能称之为关系型数据库

第二范式（确保表中的每列都和主键相关）
第二范式在第一范式的基础上更进一层。第二范式需要确保数据库表中的每一列都和主键相关，而不能只与主键的某一部分相关（主要针对联合主键而言）。也就是说在一个数据库表中，一个表只能保存一种数据，不可以把多种数据保存在同一张数据库表中，通俗讲就是说该分表的时候就分表，不要将多个表内容合并为一个表

第三范式（确保每列都和主键列直接相关，而不是间接相关）
第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。通俗讲就是当涉及到其他表项内容时设置外键进行关联，而不要加入其他表项内容。

# 数据库引擎
## Innodb
存储结构
InnoDB的数据时按【数据页】为单位来读写的，默认数据页大小为16KB。每个数据页之间通过【双向链表】的形式组织起来，物理上不连续，但是逻辑上连续。数据页内包含用户记录，InnoDB在查找某条记录时，并不能直接找到对应的行记录，而是只能获取到记录所在的页，然后将整个页面加载到内存中，在内存中遍历找到具体行。每个记录之间用单向链表的方式组织起来，为了在数据页内高效传记录，设计了一个页目录，且主键值是有序的，因此可以通过二分查找的方式进行检索从而提高效率。
![image.png](https://raw.githubusercontent.com/mowang111/image-hosting/master/typora_images/20230302141457.png)
Buffer Pool
InnoDB 存储引擎设计了一个缓冲池（Buffer Pool），来提高数据库的读写性能。Buffer Pool里面有三种结构来管理数据。
+ Free Page(空闲页)，表示此页未被使用， 位于Free链表。
+ Clean Page(干净页)，表示此页已被使用，但是页面未发生修改，位于LRU链表
+ Dirty Page(脏页)，表示此页【已被使用】且【已被修改】，其数据和磁盘上的数据已经不一致。当脏页上的数据写入磁盘后，内存数据和磁盘数据一致，那么该页就变成了干净页。

简单的LRU算法并没有被MySQL使用，因为其无法避免下面两个问题：
+ 预读失效：MySQL在加载数据页时，会提前把它相邻的数据页一并加载进来，目的时为了减少磁盘IO。但是这些被提前加载进来的数据页，可能并没有被访问，相当于这个预读是白做了，这就是预读失效。
	+ MySQL改进了LRU算法，将LRU划分了2个区域：old区域和young区域。young区域在LRU链表的前半部分，old区域则是在后半部分。young区域占整个LRU链表长度的比例可以通过参数来设置，一般young区域为old区域的2倍大小。划分这两个区域后，预读的页就只需要加入到old区域的头部，当页被真正访问的时候，才将页插入young区域的头部。如果预读的页一直没有被访问，就会从old区域移除，这样就不会影响young区域中的热点数据。
+ Buffer Pool 污染：当某一个SQL语句扫描大量的数据时，在Buffer Pool空间比较有限的情况下，可能会将Buffer Pool里的所有页都替换出去，导致大量热数据被淘汰，等这些热数据又被再次访问的时候，由于缓存未命中，就会产生大量的磁盘IO，MySQL性能就会急剧下降，这个过程被称为Buffer Pool污染。【解决方案是只有同时满足【被访问】与【在old区域停留时间超过N秒】两个条件，才会被插入到young区域头部，这样就解决了Buffer Pool污染的问题。】另外，MySQL针对young区域起始做了一个优化，为了防止young区域节点频繁移动到头部。young区域前面1/4被访问不会移动到链表头部，只有后面3/4被访问才会。

## MyISAM
存储结构
MyISAM的数据是顺序存储的。索引的B+树叶节点存放数据记录的地址，可以直接定位到数据，因此查找速度很快。

# MyISAM和InnoDB的区别
MyISAM和InnoDB是MySQL数据库的两种常用的存储引擎，它们又以下区别：
1. 事务支持：InnoDB支持事务，而MyISAM不支持。事务是数据库中的一组操作，要么全部执行成功，要么全部回滚。这使得InnoDB在需要保证数据一致性和完整性时非常有用。
2. 并发性：InnoDB支持行级锁定，而MyISAM仅支持表级锁定。这意味着InnoDB可以更好得处理高并发请求，而MyISAM的性能则可能受到锁定冲突的影响。
3. 外键约束：InnoDB支持外键约束，而MyISAM不支持。外键约束是一个表中的列，引用另一个表中的列，以确保数据的完整性和一致性。
4. 全文索引：InnoDB支持全文索引，而MyISAM仅支持全文索引的部分功能。全文索引是一种高级搜索计数，他可以在文本字段中搜索关键字，而不仅仅是完全匹配的字符串。
5. 空间占用：MyISAM比InnoDB更省空间，因为他不需要想InnoDB一样存储额外的元数据。
6. 性能：对于小型应用程序或只读数据，MyISAM比InnoDB更快。但是，对于高并发的、大型、需要事务支持的应用程序，InnoDB的性能通常更好。

# 数据库索引
## 索引的分类
根据底层数据结构划分
索引是提高查询效率的数据结构，而MySQL中用到了B+Tree和散列表（Hash表）作为索引的底层数据结构（其实也用到了跳表实现全文索引，但这不是重要考点）
1. hash索引：MySQL并没有显示支持Hash索引，而是作为内部的一种优化。具体在Innodb存储引擎里，会监控对表上二级索引的查找，如果发现某二级索引被频繁访问，二级所以成为热数据，就为之建立hash索引。
2. B+树索引：这是MySQL索引的基本实现方式。读取一个节点相当于一次磁盘I/O操作。B+Tree相比于二叉树来说，最大的优势在于查询效率很高，因为即使在数据量很大的情况，查询一个数据的磁盘I/O依然维持在3-4次。

根据数据与索引的存储关联性划分
索引又可以分为聚簇索引和非聚簇索引（二级索引），它们区别就在于叶子节点存放的是什么数据：
+ 聚簇索引的叶子节点存放的是实际数据，所有完整的用户记录都存放在聚簇索引的叶子节点；
+ 二级索引的叶子节点存放的是主键值，而不是实际数据
因为表的数据都是存放在聚簇索引的叶子节点里，所以InnoDB存储引擎一定会为表创建一个聚簇索引，且由于数据在物理上只会保存一份，所以聚簇索引只能有一个。

InnoDB在创建聚簇索引时，会根据不同的场景选择不同的列作为索引：
+ 如果有主键，默认会使用主键作为聚簇索引的索引键；
+ 如果没有主键，就选择第一个不包含NULL值的唯一列作为聚簇索引的索引键；
+ 在上面两个都没有的情况下，InnoDB将自动生成一个隐式自增id列作为聚簇索引的索引键。

唯一索引、主键的区别：
1. 主键是一种约束，是逻辑键，实际不存在；唯一索引是一种索引，是物理键，实际存在
2. 主键创建后一定包含唯一索引；唯一索引并不一定是主键。
3. 唯一索引列允许空值；而主键列不允许空值
4. 主键可以被其他表引用为外键；而唯一索引不能
5. 一个表有且只能创建一个主键；但可以创建多个唯一索引
6. 主键和唯一索引都可以有多列

## 索引优缺点
索引的优点：
+ 加快数据的检索速度
+ 减少查询中分组和排序的时间
+ 通过创建主键索引，可以保证数据库表中每一行数据的唯一性
+ 将随机I/O变为顺序I/O（B+Tree索引是有序的，会将相邻的数据都存储在一起）

索引的缺点：
+ 占用额外空间
+ 一开始增加索引时，需要创建索引表
+ 新增或删除数据时，需要维护索引表

## 索引的使用场景
索引的适用场景：
+ 等值查询
+ 范围查询
+ 匹配最左前缀（联合索引）

适合建立索引：
+ 经常作为查询条件的字段，且列上的不同值较多；
+ 频繁进行排序或分组（即进行group by或order by操作）的列。建立索引之后在B+Tree中的记录都是排序好的
+ 如果待排序的列有多个，可以在这些列上建立联合索引

不适合建立索引：
+ 更新频繁的字段
+ 不会作为查询条件的字段
+ 表记录很少的时候


## 优化索引方法
+ 使用覆盖索引
	+ 假设只需要查询商品的名称、价格，可以建立一个联合索引，即【商品ID、名称、价格】作为一个联合索引。如果索引中存在这些数据，查询将不会再次检索主键索引，从而避免回表，也减少了大量的I/O操作
+ 主键索引最好是自增的
	+ InnoDB创建主键索引默认为聚簇索引，数据被存放在了B+Tree的叶子节点上。如果使用自增主键，那么每次插入的新数据就会按顺序添加到当前索引节点的位置，不需要移动已有数据，当页面写满，就会自动开辟一个新页面，因此这种插入数据的方法效率非常高
	+ 如果使用非自增主键，由于每次插入主键的索引值都是随机的，因此每次插入新的数据时，就可能会插入到现有数据页中间的位置，这将不得不移动其他数据来满足新数据的插入，甚至需要从一个页面复制数据到另外一个页面，通常这种情况称为页分裂。页分裂可能会造成大量的内存碎片，导致索引结构不紧凑，从而影响查询效率
+ 索引最好设置为NOT NULL
	+ 索引列存在NULL会导致优化器在做索引选择的时候难以优化，比如进行索引统计时，count会忽略值为NULL的行。NULL值是一个没有意义的值，但是它会占用物理空间。
+ 防止索引失效
	+ 索引失效的情况
		+ 以%开头的like查询
		+ 对索引列进行函数运算，正则表达式
		+ 联合索引的情况下，不满足最左原则
		+ MySQL估计使用索引比全表扫描更慢的情况
		+ 用or分割开的条件，如果or前的条件中的列有索引，而后面的列中没有索引，那么涉及的索引都不会被用到
		+ 使用负向查询（not, not in, not like, <>, !=, !>, !<）不会使用索引


# 数据库为什么用B+树做索引
要设计一个MySQL的索引数据结构，不仅仅考虑数据结构增删改的时间复杂度，更重要的是要考虑磁盘I/O的操作次数。因为索引和记录都是存放在硬盘，硬盘是一个非常慢的存储设备，在查询数据的时候，最好能用尽可能少的磁盘I/O的操作完成。
+ 二分查找树虽然是一个天然的二分结构，能很好的利用二分查找快速定位数据，但是它存在一种极端情况，每当插入的元素都是树内最大的元素，就会导致二分查找树退化为一个链表，此时查询的复杂度就会从O(logn)降低为O(n)。
+ 为了解决二分查找树退化成链表的问题，就出现了自平衡二叉树，保证查询操作的时间复杂度一直维持在O(logn)。但是它本质上还是一个二叉树，每个节点只能有2个子节点，随着元素的增多，树的高度会越来越高。而树的高度决定了磁盘I/O操作的次数
+ B树和B+树都是通过多叉树的方式，将树的高度变矮，所以这两个数据结构非常适合检索存于磁盘中的数据。

B 与 B+树的差异
+ 单点查询
	+ B树进行单个索引查询时，最快可以在O(1)的时间代价内就查到，从平均时间代价来看，会比B+树稍快一些。但是B树的查询波动会比较大，因为每个节点既存索引又存记录，所以有时候访问到了非叶子节点就可以找到索引，而有时需要访问到叶子节点才能找到索引
	+ B+树的非叶子节点不存放实际的记录数据，仅存放索引，因此在数据量相同的情况下，相比既存索引又存记录的B树，B+树的非叶子节点可以存放更多的索引，因此B+树可以比B树更【矮胖】，查询底层节点的磁盘I/O次数会更少/
+ 范围查询
	+ 因为B+树所有叶子节点间还有一个双向链表进行链接，这种设计对范围查找非常有帮助。而B树没有将所有叶子节点用链表串联起来的结构，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘I/O操作，范围查询效率不如B+树。
+ 插入和删除效率
	+ B+树有大量的冗余节点，当删除一个节点的时候，直接从叶子节点中删除，甚至可以不动非叶子节点，这样删除非常快。B+树的插入也是一样，有冗余节点，插入可能存在节点的分裂（如果节点饱和），但是最多只涉及树的一条路径。而且B+树会自动平衡，不需要更多复杂的算法。因此，B+树的插入和删除效率更高。
+ 因此，存在大量范围检索的场景，适合使用B+树，比如mysql。而对于大量的单个索引查询的场景，可以考虑B树，比如nosql的MongoDB


## 联合索引与最左匹配原则
如果频繁地使用相同的几个字段查询，就可以考虑建立这几个字段的联合索引来提高查询效率。比如对于联合索引test_col1_col2_col3，实际建立了（col1）、（col1,col2）、（col1,col2,col3）三个索引。联合索引的主要优势是减少结果集数量；如果根据col1、col2、col3的单列索引进行查询，需要分别得到`num[i]`个结果，然后再取交集；而如果使用联合索引查询，只会得到很少的一段数据。

最左匹配原则：这些索引能够被包含col1、(col1 col2)、（col1 col2 col3）的查询利用到，但是不能够被col2、（col2、col3）的等值查询利用到。这与底层实现有关。联合索引的最左匹配原则，在遇到范围查询（>、<、between、like这种）的时候，就会停止匹配，也就是范围列可以用到联合索引，但是范围列后面的列无法用到联合索引。但是如果是>=、<=时可以继续走索引。

## count(...)查询效率
按照性能排序：`count(*) = count(1) > count(主键字段) > count(字段)`（都是对记录进行逐条判断，后面两个有额外判断是否为NULL的步骤）
+ `count(1)、count(*)、count(主键字段)`在执行的时候，如果表里存在二级索引，优化器就会选择二级索引进行扫描。所以，如果要执行`count(1)、count(*)、count(主键字段)`时，尽量在数据表上建立二级索引，这样优化器会自动采用key_len最小的二级索引进行扫描，相比于主键索引效率会高一些。
+ 不要使用`count(字段)`来统计记录个数，因为它的效率是最差的，会采用全表扫描的方式来统计。

使用MyISAM引擎时，执行count函数只需要O(1)复杂度，这是因为每张MyISAM的数据表都有一个meta信息存储了row_count值，由表级锁保证一致性，所以直接读取row_count值就是count函数的执行结果

而InnoDB存储引擎是支持事务的，同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB表“应该返回多少行“也是不确定的，所以无法像MyISAM一样，只维护一个row_count变量。而当带上where条件语句之后，MyISAM跟InnoDB都需要扫描表来进行记录个数的统计。


如何优化`count(*)`?
+ 近似值：可以使用show table status 或者explain命令来进行估算。执行explain命令效率是很高的，因为它不会真正的去查询。
+ 额外表保存计数值：如果是想精确的获取表的记录总数，我们可以将这个计数值保存到单独的一张计数表中。当我们在数据表插入一条记录的同时，将计数表的计数字段+1。在新增和删除操作时，额外维护这个计数表


# 事务
一个事务是一组对数据库中数据操作的集合。无论集合中有多少操作，对于用户来说，只是对数据库状态的一个原子改变。

## ACID特性与实现
1. 原子性（Atomicity）：指一个事务中的操作，要么全部成功，要么全部失败，如果失败就回滚到事务开始前的状态
2. 一致性（Consistency）：指事务必须使数据库从一个一致性状态变换到另一个一致性状态。比如转账，A账户和B账户相互转账，无论如何操作，A、B账户的总金额必须是不变的
3. 隔离性（Isolation）：指当多个用户并发的访问数据库时，事务之间的并发是隔离的。比如两个并发的事务T1和T2，T1要么在T2开始前执行，要么在T2结束后执行。
4. 持久性（Durability）：指事务一旦被提交，数据库中数据的改变就是永久性的。

+ 回滚日志：发生错误或者需要回滚的事务能够成功回滚（原子性）
	+ Innodb存储引擎层生成的日志，当事务尝试对数据进行修改时，会先记录到回滚日志undo log中，然后再对数据库中的对应行进行写入。在异常发生时，对已经执行的操作进行回滚。主要用于事务回滚和MVCC。
+ 重做日志：在事务提交后，数据没来得及写回磁盘就宕机时，能够成功恢复数据（持久性）
	+ Innodb存储引擎层生成的日志，重做日志由两部分组成，一是内存中的重做日志缓冲区，另一个就是在磁盘上的重做日志文件。当事务尝试对数据进行修改时，会先将数据从磁盘读入内存，并更新内存中缓存的数据，然后生成一条记录并写入重做日志缓存，当事务真正提交时，会将重做日志缓存中的内容刷到重做日志文件中，再将内存中的数据更新到磁盘上。
	+ 在InnoDB中，重做日志都是以512字节的块的形式进行存储的，同时因为块的大小与磁盘扇区大小相同，所以重做日志的写入可以保证原子性，不会由于机器断电导致重做日志仅写入一半而留下脏数据。除了所有对数据库的修改会产生重做日志，因为回滚日志也是需要持久存储的，它们也会创建对应的重做日志，在发生错误后，数据库重启时会从重做日志中找出未被更新到数据库磁盘中的日志重新执行以满足事务的持久性。
+ 归档日志（binlog）:是Server层生成的日志，binlog文件是记录了所有数据库表结构变更和表数据修改的日志，不会记录查询的操作。主要用于数据备份和主从复制

redo log 和 binlog有什么区别？
+ 适用对象不同：binlog是Server层实现的日志，所有存储引擎都可以使用；redo log是Innodb存储引擎实现的日志
+ 文件格式不同：binlog有3中格式类型，分别是STATEMENT（默认格式，记录操作）、ROW（记录数据行）、MIXED（自动混合使用）；redo log记录的是在某个数据页做了什么修改
+ 写入方式不同：binlog是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志。redo log是循环写，日志空间大小是固定的，全部写满就从头开始，保存未被刷入磁盘的脏页日志。
+ 用途不同：binlog用于数据备份、主从复制；redo log用于断电等故障恢复。

MVCC或锁机制保证隔离性，而一致性则是通过持久性+原子性+隔离性来保证

## 两阶段提交
在持久化redo log 和binlog这两份日志的时候，如果出现半成功的状态，就会造成主从环境的数据不一致性。这是因为redo log影响主库的数据，binlog影响从库的数据，所以redo log和binlog必须保持一致才能保证主从数据一致。MySQL为了避免出现两份日志之间逻辑不一致的问题，使用了【两阶段提交】来解决，两阶段提交其实是分布式事务一致性协议，它可以保证多个逻辑操作要么全部成功，要么全部失败，不会出现半成功的状态。两阶段提交把单个事务的提交拆分成了2个阶段，分别是【准备（Prepare）阶段】和【提交（Commit）阶段  】，每个阶段都由协调者（Coordinator）和参与者（Participant）共同完成。
> 注意，不要把提交（Commit）阶段和commit语句混淆了，commit语句执行的时候，会包含提交（Commit）阶段。

在MySQL的InnoDB存储引擎开启binlog的情况下，MySQL会同时维护binlog日志与redo log，当客户端执行commit语句或者在自动提交的情况下，为了保证这两个日志的一致性，MySQL内部开启了一个XA事务，分两阶段来完成XA事务的提交，就是将redo log的写入拆成了两个步骤：prepare和commit，中间再穿插写入binlog，具体如下：
+ prepare阶段：将XID（内部XA事务的ID）写入到redo log，同时将redo log 对应的事务状态设置为prepare, 然后将redo log刷新到磁盘
+ commit阶段：把XID写入到binlog，然后将binlog刷新到磁盘，接着调用存储引擎的提交事务接口，将redo log状态设置为commit
异常发生时比较redolog和binlog中的XID，若一致则提交事务，否则回滚事务

两阶段提交虽然保证了两个日志文件的数据一致性，但是性能很差，主要由两个方面的影响：
+ 磁盘I/O次数高：每个事务提交都会进行两次fsync（刷盘），一次是redo log刷盘，另一次是binlog刷盘
+ 锁竞争激烈：两阶段提交虽然能够保证【单事务】两个日志的内容一致，但是在【多事务】的情况下，却不能保证两者的提交顺序一致，因此，在两阶段提交的流程基础上，还需要加一个锁来保证提交的原子性，从而保证多事务的情况下，两个日志的提交顺序一致

组提交
MySQL引入了binlog组提交（group commit）机制，当由多个事务提交的时候，会将多个binlog刷盘操作合并成一个，从而减少磁盘I/O的次数。
引入了组提交机制后，prepare阶段不变，只针对commit阶段，将commit阶段拆分成三个过程：
+ flush阶段：多个事务按进入的顺序将binlog从cache写入文件(不刷盘)
+ sync阶段：对binlog文件做fsync操作（多个事务的binlog合并一次刷盘）
+ commit阶段：各个事务按顺序做InnoDB commit操作
上面每个阶段都有一个队列，每个阶段都有锁进行保护，因此保证了事务写入的顺序，第一个进入队列的事务会称为leader，leader领导所在的队列的所有事务，全却负责整队的操作，完成后通知队内其他事务操作结束。对每个阶段引入队列后，锁就只针对每个队列进行保护，不在锁住提交事务的整个过程，可以看出，锁粒度减少了，这样就使得多个阶段可以并发执行，从而替身效率

## 隔离性问题
若不考虑隔离性，则会出现以下问题：
1. 脏读：指一个事务在处理数据的过程中，读取到另一个未提交事务的数据
2. 不可重复读：指对于数据库中的某个数据（同一个数据项），一个事务内多次查询却返回了不同的结果。这是由于在查询过程中，数据被另外一个事务修改并提交了。可通过行锁解决。
3. 幻读：

